{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import List,Optional, Dict, Any, Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# llama index imports\n",
    "import llama_index.core\n",
    "from llama_index.core import SimpleDirectoryReader,VectorStoreIndex,SummaryIndex, StorageContext, Settings, load_index_from_storage, Response\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core.node_parser import SentenceSplitter, CodeSplitter, LangchainNodeParser\n",
    "from llama_index.core.tools import FunctionTool,QueryEngineTool\n",
    "from llama_index.core.vector_stores import MetadataFilters,FilterCondition\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "from llama_index.readers.file import IPYNBReader, PandasCSVReader\n",
    "from llama_index.experimental.query_engine import PandasQueryEngine\n",
    "from llama_index.experimental.query_engine.pandas import (\n",
    "    PandasInstructionParser,\n",
    ")\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.query_pipeline import (\n",
    "    QueryPipeline as QP,\n",
    "    Link,\n",
    "    InputComponent,\n",
    "    AgentFnComponent,\n",
    "    AgentInputComponent,\n",
    "    CustomQueryComponent,\n",
    "    FnComponent,\n",
    "    RouterComponent,\n",
    ")\n",
    "from llama_index.experimental.query_engine import PandasQueryEngine\n",
    "from llama_index.readers.file import IPYNBReader, PandasCSVReader\n",
    "from llama_index.experimental.query_engine import PandasQueryEngine\n",
    "from llama_index.experimental.query_engine.pandas import (\n",
    "    PandasInstructionParser,\n",
    ")\n",
    "\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "\n",
    "# llama index agent imports\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker, ReActAgent, Task, AgentChatResponse, AgentRunner, QueryPipelineAgentWorker\n",
    "\n",
    "# llama index llms and embeddings imports\n",
    "from llama_index.llms.mistralai import MistralAI\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.mistralai import MistralAIEmbedding\n",
    "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# custom package imports\n",
    "from llama_index.packs.tables.chain_of_table.base import ChainOfTableQueryEngine, serialize_table\n",
    "\n",
    "# langchain imports\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
    "\n",
    "# uncertainty imports\n",
    "from crepes import WrapClassifier, ConformalClassifier\n",
    "from venn_abers import VennAbersCalibrator, VennAbers\n",
    "\n",
    "# tools\n",
    "import nest_asyncio # to allow running async functions in jupyter\n",
    "import chromadb # persistent storage for vectors\n",
    "# import nbconvert\n",
    "import tree_sitter\n",
    "import tree_sitter_languages\n",
    "import phoenix as px\n",
    "from pyvis.network import Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [phoenix.session.session] Existing running Phoenix instance detected! Shutting it down and starting a new instance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒ To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "ðŸ“– For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "temperture = 0.0 #for deterministic results\n",
    "\n",
    "llm_model = \"mistral-large-latest\"\n",
    "# llm_model = \"codestral-latest\"\n",
    "MISTRAL_API_KEY =  \"BWdlihu9sUh5P2g3bHnzjAaHiT4anTVH\"\n",
    "os.environ[\"MISTRAL_API_KEY\"] = MISTRAL_API_KEY\n",
    "llm = MistralAI(model=llm_model, temperature=temperture)\n",
    "\n",
    "# llm_model = \"gpt-3.5-turbo\"\n",
    "# # llm_model = \"gpt-4\"\n",
    "# OPENAI_API_KEY =  \"something\"\n",
    "# os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "# llm = OpenAI(model=llm_model, temperature=temperture)\n",
    "\n",
    "# llm_model = \"codellama\"\n",
    "# llm = Ollama(model=llm_model, request_timeout=1200.0, base_url=\"http://localhost:11434\", temperature=temperture)\n",
    "\n",
    "nest_asyncio.apply() # to allow running async functions in jupyter\n",
    "px.launch_app()\n",
    "llama_index.core.set_global_handler(\"arize_phoenix\")\n",
    "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading file\n",
    "file_path = \"./data_csv/Sepsis_Processed_IC.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Pipeline Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_str = (\n",
    "    \"1. Convert the query to executable Python code using Pandas.\\n\"\n",
    "    \"2. The final line of code should be a Python expression that can be called with the `eval()` function.\\n\"\n",
    "    \"3. The code should represent a solution to the query.\\n\"\n",
    "    \"4. PRINT ONLY THE EXPRESSION.\\n\"\n",
    "    \"5. Do not quote the expression.\\n\"\n",
    "    \"6. Add axis labels, legend, and title when creating a plot.\\n\"\n",
    ")\n",
    "\n",
    "pandas_prompt_str = (\n",
    "    \"You are working with a pandas dataframe in Python.\\n\"\n",
    "    \"The name of the dataframe is `df`. You should interpret the columns of the dataframe as follows: \\n\"\n",
    "    \"1) Each row represents patient data related to sepsis diagnosis.\\n\"\n",
    "    \"2) The Target column indicates whether the patient had sepsis.\\n\"\n",
    "    \"3) The duration_since_reg column describes the patient's stay after admission in days.\\n\"\n",
    "    \"4) Diagnosis-related columns detail specific diagnostic results and associated codes.\\n\"\n",
    "    \"5) The dataset includes patient demographics age, clinical measurements (crp, lacticacid, leucocytes), and diagnostic procedures (diagnosticartastrup, diagnosticblood, etc.).\\n\"\n",
    "    \"6) The dataframe also records clinical criteria for sepsis (sirscritheartrate, sirscritleucos, etc.), resource usage, and event transitions (e.g., CRP => ER Triage).\\n\"\n",
    "    \"7) Additional columns capture organ dysfunction, hypotension, hypoxia, suspected infection, and treatment details like infusions and oliguria.\\n\"\n",
    "    \"8) The dataset covers the transitions between various clinical events, highlighting the pathways in the patient's diagnostic and treatment journey.\\n\"\n",
    "    \"9) ER here refers to the emergency room.\\n\"\n",
    "    \"10) You only answer questions related to the dataframe.\\n\"\n",
    "    \"11) If you do not know the answer, then say you do not know.\\n\\n\"\n",
    "\n",
    "    \"This is the result of `print(df.head())`:\\n\"\n",
    "    \"{df_str}\\n\\n\"\n",
    "    \n",
    "    \"Follow these instructions:\\n\"\n",
    "    \"{instruction_str}\\n\"\n",
    "    \"Query: {query_str}\\n\\n\"\n",
    "    \"Expression:\"\n",
    ")\n",
    "response_synthesis_prompt_str = (\n",
    "    \"Given an input question, synthesize a response from the query results.\\n\"\n",
    "    \"Query: {query_str}\\n\\n\"\n",
    "    \"Pandas Instructions (optional):\\n{pandas_instructions}\\n\\n\"\n",
    "    \"Pandas Output: {pandas_output}\\n\\n\"\n",
    "    \"Response: \"\n",
    ")\n",
    "\n",
    "code_execution = (\n",
    "    \"Execute the code to generate the output and include explanation.\\n\"\n",
    "    \"Query: {query_str}\\n\\n\"\n",
    "    \"Pandas Output: {pandas_output}\\n\\n\"\n",
    "    \"Response: \"\n",
    ")\n",
    "\n",
    "\n",
    "class CustomPandasInstructionParser(PandasInstructionParser):\n",
    "    def parse(self, text):\n",
    "        # Prepend the necessary import statements\n",
    "        imports = \"import pandas as pd\\nimport matplotlib.pyplot as plt\\n\"\n",
    "        # Combine the imports with the code generated by the model\n",
    "        code = imports + text\n",
    "        return code\n",
    "\n",
    "\n",
    "pandas_prompt = PromptTemplate(pandas_prompt_str).partial_format(\n",
    "    instruction_str=instruction_str, df_str=df.head(5)\n",
    ")\n",
    "\n",
    "pandas_output_parser = PandasInstructionParser(df)\n",
    "# pandas_output_parser = CustomPandasInstructionParser(df)\n",
    "response_synthesis_prompt = PromptTemplate(response_synthesis_prompt_str)\n",
    "code_execution_prompt = PromptTemplate(code_execution)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define query pipeline with modules\n",
    "qp_table = QP(\n",
    "    modules={\n",
    "        \"input\": InputComponent(),\n",
    "        \"pandas_prompt\": pandas_prompt,\n",
    "        \"llm1\": llm,\n",
    "        \"pandas_output_parser\": pandas_output_parser,\n",
    "        \"response_synthesis_prompt\": response_synthesis_prompt,\n",
    "        \"llm2\": llm,\n",
    "        \"code_execution\": code_execution_prompt,\n",
    "        \"llm3\": llm,\n",
    "    },\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "qp_table.add_chain([\"input\", \"pandas_prompt\", \"llm1\", \"pandas_output_parser\"])\n",
    "qp_table.add_links(\n",
    "    [\n",
    "        Link(\"input\", \"response_synthesis_prompt\", dest_key=\"query_str\"),\n",
    "        Link(\n",
    "            \"llm1\", \"response_synthesis_prompt\", dest_key=\"pandas_instructions\"\n",
    "        ),\n",
    "        Link(\n",
    "            \"pandas_output_parser\",\n",
    "            \"response_synthesis_prompt\",\n",
    "            dest_key=\"pandas_output\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "qp_table.add_link(\"response_synthesis_prompt\", \"llm2\")\n",
    "\n",
    "qp_table.add_links(\n",
    "    [\n",
    "        Link(\"input\", \"code_execution\", dest_key=\"query_str\"),\n",
    "        Link(\n",
    "            \"pandas_output_parser\",\n",
    "            \"code_execution\",\n",
    "            dest_key=\"pandas_output\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "qp_table.add_link(\"code_execution\", \"llm3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qp_table.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"qp_table.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x24c7bcbe740>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create diagram of the query pipeline\n",
    "net.from_nx(qp_table.clean_dag)\n",
    "net.show(\"qp_table.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Pipeline run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query_str: how many positive cases?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_prompt with input: \n",
      "query_str: how many positive cases?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm1 with input: \n",
      "messages: You are working with a pandas dataframe in Python.\n",
      "The name of the dataframe is `df`. You should interpret the columns of the dataframe as follows: \n",
      " 1) Each row represents patient data related to sep...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_output_parser with input: \n",
      "input: assistant: df['Target'].sum()\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_prompt with input: \n",
      "query_str: how many positive cases?\n",
      "pandas_instructions: assistant: df['Target'].sum()\n",
      "pandas_output: 98\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm2 with input: \n",
      "messages: Given an input question, synthesize a response from the query results.\n",
      "Query: how many positive cases?\n",
      "\n",
      "Pandas Instructions (optional):\n",
      "df['Target'].sum()\n",
      "\n",
      "Pandas Output: 98\n",
      "\n",
      "Response: \n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# run query\n",
    "response = qp_table.run(\n",
    "    query_str=\"how many positive cases?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the data provided, there are 98 positive cases.\n"
     ]
    }
   ],
   "source": [
    "# query result\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query_str: what is the average time patients spend in the hospital?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_prompt with input: \n",
      "query_str: what is the average time patients spend in the hospital?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm1 with input: \n",
      "messages: You are working with a pandas dataframe in Python.\n",
      "The name of the dataframe is `df`.\n",
      "This is the result of `print(df.head())`:\n",
      "  case_id  Target  age  max_activity_count  duration_since_reg  crp  \\\n",
      "0...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_output_parser with input: \n",
      "input: assistant: df['duration_since_reg'].mean()\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_prompt with input: \n",
      "query_str: what is the average time patients spend in the hospital?\n",
      "pandas_instructions: assistant: df['duration_since_reg'].mean()\n",
      "pandas_output: 11.568710217755443\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm2 with input: \n",
      "messages: Given an input question, synthesize a response from the query results.\n",
      "Query: what is the average time patients spend in the hospital?\n",
      "\n",
      "Pandas Instructions (optional):\n",
      "df['duration_since_reg'].mean()\n",
      "...\n",
      "\n",
      "\u001b[0mfinal response: ================================================================================================================================================================================================\n",
      "Based on the data provided, the average time patients spend in the hospital is approximately 11.57 days.\n"
     ]
    }
   ],
   "source": [
    "# run query\n",
    "response = qp_table.run(\n",
    "    query_str=\"what is the average time patients spend in the hospital?\",\n",
    ")\n",
    "# query result\n",
    "print(\"final response: ================================================================================================================================================================================================\")\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query_str: visualize the age distribution?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_prompt with input: \n",
      "query_str: visualize the age distribution?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm1 with input: \n",
      "messages: You are working with a pandas dataframe in Python.\n",
      "The name of the dataframe is `df`. You should interpret the columns of the dataframe as follows: \n",
      "1) Each row represents patient data related to seps...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_output_parser with input: \n",
      "input: assistant: df['age'].plot(kind='hist', bins=20, color='skyblue', edgecolor='black', title='Age Distribution', xlabel='Age', ylabel='Frequency')\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_prompt with input: \n",
      "query_str: visualize the age distribution?\n",
      "pandas_instructions: assistant: df['age'].plot(kind='hist', bins=20, color='skyblue', edgecolor='black', title='Age Distribution', xlabel='Age', ylabel='Frequency')\n",
      "pandas_output: Axes(0.125,0.11;0.775x0.77)\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module code_execution with input: \n",
      "query_str: visualize the age distribution?\n",
      "pandas_output: Axes(0.125,0.11;0.775x0.77)\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm2 with input: \n",
      "messages: Given an input question, synthesize a response from the query results.\n",
      "Query: visualize the age distribution?\n",
      "\n",
      "Pandas Instructions (optional):\n",
      "df['age'].plot(kind='hist', bins=20, color='skyblue', edg...\n",
      "\n",
      "\u001b[0mfinal response: ================================================================================================================================================================================================\n",
      "The age distribution can be visualized using a histogram plot with 20 bins. The plot will show the frequency of different age groups, allowing for a clear understanding of the distribution.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run query\n",
    "response = qp_table.run(\n",
    "    query_str=\"visualize the age distribution?\",\n",
    ")\n",
    "# query result\n",
    "print(\"final response: ================================================================================================================================================================================================\")\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Agent Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "def evaluate_model(model_name:str, threshold:int = -1) -> dict:\n",
    "    \"\"\"Load the trained model, evaluation data and evaluate the loaded model.\"\"\"\n",
    "    from sklearn.metrics import roc_auc_score, roc_auc_score, average_precision_score, confusion_matrix, f1_score, matthews_corrcoef\n",
    "    from joblib import load\n",
    "    \n",
    "    model_save_path = 'models'\n",
    "    model = load(f'./{model_save_path}/{model_name}.joblib')\n",
    "    X_test = pd.read_csv('./data_python/Sepsis_X_test.csv')\n",
    "    y_test = pd.read_csv('./data_python/Sepsis_y_test.csv')\n",
    "\n",
    "    pred_prob = model.predict_proba(X_test) # get the prediction probabilities for the test set\n",
    "    predictions = model.predict(X_test) # get the predictions for the test set\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, pred_prob[:,1]) # calculate the roc auc score\n",
    "    average_precision = average_precision_score(y_test, pred_prob[:,1]) # calculate the\n",
    "    best_threshold = model.best_threshold_\n",
    "\n",
    "    if threshold > 0:\n",
    "        predictions = np.where(pred_prob[:,1] > threshold, 1, 0)\n",
    "        mcc = matthews_corrcoef(y_test, predictions)\n",
    "        f1_macro = f1_score(y_test, predictions, average='macro')\n",
    "        cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "    else:\n",
    "        mcc =  matthews_corrcoef(y_test, predictions)\n",
    "        f1_macro = f1_score(y_test, predictions, average='macro')\n",
    "        cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "    return {\"roc_auc\":roc_auc, \"average_precision\":average_precision, \"mcc\":mcc, \"f1_macro\":f1_macro, \"confusion_matrix\":cm, \"best_threshold\":best_threshold}\n",
    "\n",
    "# uncertainty quantification\n",
    "def conformal_prediction(model_name:str, alpha:int = -1) -> dict:\n",
    "    \"\"\"Load the trained model, do uncertainty quantification on the loaded model and return the coverage and average width of the prediction sets.\"\"\"\n",
    "    from joblib import load\n",
    "    from crepes import WrapClassifier\n",
    "    \n",
    "    \"\"\" loading the model and data\"\"\"\n",
    "    model_save_path = 'models'\n",
    "    model = load(f'./{model_save_path}/{model_name}.joblib')\n",
    "    X_cal = pd.read_csv('./data_python/Sepsis_X_cal.csv')\n",
    "    y_cal = pd.read_csv('./data_python/Sepsis_y_cal.csv').to_numpy().reshape(-1)\n",
    "    X_test = pd.read_csv('./data_python/Sepsis_X_test.csv')\n",
    "    y_test = pd.read_csv('./data_python/Sepsis_y_test.csv').to_numpy().reshape(-1)\n",
    "\n",
    "    \"\"\"calibrating the model\"\"\"\n",
    "    wrapped_clf = WrapClassifier(model) \n",
    "    wrapped_clf.calibrate(X_cal, y_cal)\n",
    "    \n",
    "    \"\"\" uncertainty quantification - coverage and average width of the prediction sets\"\"\"\n",
    "    if alpha > 0:\n",
    "        prediction_sets = wrapped_clf.predict_set(X_test, confidence=(1-alpha))\n",
    "        coverage = np.mean([prediction_sets[i][y_test[i]] for i in range(len(prediction_sets))])\n",
    "        widths = [np.sum(pred) for pred in prediction_sets] \n",
    "        average_width = np.mean(widths)\n",
    "    else:\n",
    "        alpha = 0.1\n",
    "        prediction_sets = wrapped_clf.predict_set(X_test, confidence=(1-alpha))\n",
    "        coverage = np.mean([prediction_sets[i][y_test[i]] for i in range(len(prediction_sets))])\n",
    "        widths = [np.sum(pred) for pred in prediction_sets] \n",
    "        average_width = np.mean(widths)\n",
    "    \n",
    "    return {\"coverage\":coverage, \"average_width\":average_width}\n",
    "\n",
    "# venn abers\n",
    "def venn_abers_calibration(model_name:str) -> dict:\n",
    "    \"\"\" Load the trained model, do uncertainty quantification using Venn-Abers calibration and generate the prediction intervals for the test set.\"\"\"\n",
    "\n",
    "    # load the trained model\n",
    "    from venn_abers import VennAbersCalibrator, VennAbers\n",
    "    from joblib import load\n",
    "\n",
    "    model_save_path = 'models'\n",
    "    plot_save_path = 'plots'\n",
    "\n",
    "    va = VennAbersCalibrator() # initialize the Venn-Abers calibrator\n",
    "\n",
    "    # load the model and data\n",
    "    model = load(f'./{model_save_path}/{model_name}.joblib')\n",
    "    X_cal = pd.read_csv('./data_python/Sepsis_X_cal.csv')\n",
    "    y_cal = pd.read_csv('./data_python/Sepsis_y_cal.csv').to_numpy().reshape(-1)\n",
    "    X_test = pd.read_csv('./data_python/Sepsis_X_test.csv')\n",
    "    y_test = pd.read_csv('./data_python/Sepsis_y_test.csv').to_numpy().reshape(-1)\n",
    "\n",
    "    # model results\n",
    "    prediction_prob_cal = model.predict_proba(X_cal)\n",
    "    prediction_prob_test = model.predict_proba(X_test)\n",
    "\n",
    "    # get calibrated prediction probabilities and predicted class labels\n",
    "    p_prime = va.predict_proba(p_cal=prediction_prob_cal, y_cal=y_cal, p_test=prediction_prob_test, p0_p1_output=True) # probability intervals for class 1\n",
    "    y_pred = np.argmax(va.predict(p_cal=prediction_prob_cal, y_cal=y_cal, p_test=prediction_prob_test), axis=1) # predicted class labels\n",
    "\n",
    "    # get the prediction probabilities and intervals for class 1\n",
    "    y_pred_interval_p1 = p_prime[1] # intervals for class 1\n",
    "    y_pred_p1 = p_prime[0][:, 1] # predicted probability of class 1\n",
    "\n",
    "    # create dataframe using the prediction probabilities and intervals for class 1\n",
    "    df = pd.DataFrame({'p0': y_pred_interval_p1[:,0], 'p1': y_pred_interval_p1[:,1], 'p of class_1': y_pred_p1, 'y': y_test})\n",
    "    display(df.head(10))\n",
    "\n",
    "\n",
    "    # sort the predictions based on the predicted probability of class 1\n",
    "    sorted_indices = np.argsort(y_pred_p1) # sort the predicted probabilities of class 1\n",
    "    y_pred_interval_p1 = y_pred_interval_p1[sorted_indices]\n",
    "    y_pred_p1 = y_pred_p1[sorted_indices]\n",
    "    y_test_sorted = y_test[sorted_indices]\n",
    "    y_pred_sorted = y_pred[sorted_indices]\n",
    "\n",
    "    # calculate the lower and upper bounds of the intervals for class 1\n",
    "    lower_bound = y_pred_p1 - y_pred_interval_p1[:, 0] # calculate lower bound by subtracting the lower interval from the predicted probability of class 1\n",
    "    upper_bound = y_pred_interval_p1[:, 1] - y_pred_p1 # calculate upper bound by subtracting the predicted probability of class 1 from the upper interval \n",
    "    bounds = [lower_bound, upper_bound]\n",
    "\n",
    "    # plot the predicted probability of class 1 with intervals\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.errorbar(np.arange(len(y_pred_p1)), y_pred_p1, yerr=bounds, fmt='o', ecolor='tab:red', capsize=5, label='Predicted Probability of Class 1')\n",
    "    # plt.scatter(np.arange(len(y_pred_p1)), y_test_sorted, color='tab:blue', label='Actual Label')\n",
    "    plt.axhline(y=0.5, color='black', linestyle='--', linewidth=1)\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xlabel('Test Sample')\n",
    "    plt.title('Predicted Probability of Class 1 with intervals')\n",
    "    plt.savefig(f'./{plot_save_path}/prediction_intervals.png')\n",
    "    plt.close()\n",
    "\n",
    "    return {\"plot_path\":f'./{plot_save_path}/prediction_intervals.png'}\n",
    "\n",
    "# create tools\n",
    "evaluate_model_tool = FunctionTool.from_defaults(name=\"evaluate_model\", fn=evaluate_model)\n",
    "conformal_prediction_tool = FunctionTool.from_defaults(name=\"conformal_prediction\", fn=conformal_prediction)\n",
    "venn_abers_calibration_tool = FunctionTool.from_defaults(name=\"venn_abers_calibration\", fn=venn_abers_calibration)\n",
    "tools = [conformal_prediction_tool, evaluate_model_tool, venn_abers_calibration_tool]\n",
    "\n",
    "top_level_agent_prompt = \"\"\"\n",
    "                You are designed to help with a variety of tasks, from answering questions \\\n",
    "                to providing summaries to other types of analyses.\n",
    "\n",
    "                ## Tools\n",
    "                You have access to a wide variety of tools. You are responsible for using\n",
    "                the tools in any sequence you deem appropriate to complete the task at hand.\n",
    "                This may require breaking the task into subtasks and using different tools\n",
    "                to complete each subtask.\n",
    "\n",
    "                You have access to the following tools:\n",
    "                {tool_desc}\n",
    "\n",
    "                ## Output Format\n",
    "                To answer the question, please use the following format.\n",
    "\n",
    "                ```\n",
    "                Thought: I need to use a tool to help me answer the question.\n",
    "                Action: tool name (one of {tool_names}) if using a tool.\n",
    "                Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\n",
    "                ```\n",
    "\n",
    "                Please ALWAYS start with a Thought.\n",
    "\n",
    "                Please use a valid JSON format for the Action Input. Do NOT do this {{'input': 'hello world', 'num_beams': 5}}.\n",
    "\n",
    "                If this format is used, the user will respond in the following format:\n",
    "\n",
    "                ```\n",
    "                Observation: tool response\n",
    "                ```\n",
    "\n",
    "                You should keep repeating the above format until you have enough information\n",
    "                to answer the question without using any more tools. At that point, you MUST respond\n",
    "                in the one of the following two formats:\n",
    "\n",
    "                ```\n",
    "                Thought: I can answer without using any more tools.\n",
    "                Answer: [your answer here]\n",
    "                ```\n",
    "\n",
    "                ```\n",
    "                Thought: I cannot answer the question with the provided tools.\n",
    "                Answer: Sorry, I cannot answer your query.\n",
    "                ```\n",
    "\n",
    "                ## Additional Rules\n",
    "                - You MUST obey the function signature of each tool. Do NOT pass in no arguments if the function expects arguments.\n",
    "                - For queries that require uncertainty quantification (like 'what is the coverage and average width of the prediction sets'), use 'conformal_prediction'.\n",
    "                - For queries that requires to evaluate the model (like 'what is the f1 score of the model'), use 'evaluate_model'.\n",
    "                - For queries that require Venn-Abers calibration (like 'generate the prediction intervals for the test set'), use 'venn_abers_calibration'.\n",
    "                - Answer only the questions asked.\n",
    "\n",
    "                ## Current Conversation\n",
    "                Below is the current conversation consisting of interleaving human and assistant messages.\n",
    "                \"\"\"\n",
    "model_agent_prompt = PromptTemplate(top_level_agent_prompt)\n",
    "agent_model = ReActAgent.from_tools(tools=tools, \n",
    "                                     llm=llm,\n",
    "                                     verbose=True)\n",
    "agent_model.update_prompts({\"agent_worker:system_prompt\": model_agent_prompt})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Agent run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: I need to use a tool to help me answer the question.\n",
      "Action: venn_abers_calibration\n",
      "Action Input: {'model_name': 'XGBoost'}\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "      <th>p of class_1</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.061006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.039121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.048428</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         p0        p1  p of class_1  y\n",
       "0  0.142857  0.190476      0.181818  0\n",
       "1  0.047619  0.142857      0.130435  0\n",
       "2  0.000000  0.034483      0.033333  0\n",
       "3  0.017544  0.035088      0.034483  0\n",
       "4  0.750000  1.000000      0.800000  1\n",
       "5  0.017544  0.063830      0.061006  0\n",
       "6  0.017544  0.040000      0.039121  0\n",
       "7  0.000000  0.027778      0.027027  0\n",
       "8  0.017544  0.035714      0.035077  0\n",
       "9  0.017544  0.050000      0.048428  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mObservation: {'plot_path': './plots/prediction_intervals.png'}\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools.\n",
      "Answer: The prediction intervals for the XGBoost model have been generated and saved in a plot. You can find the plot at the following path: './plots/prediction_intervals.png'.\n",
      "\u001b[0mThe prediction intervals for the XGBoost model have been generated and saved in a plot. You can find the plot at the following path: './plots/prediction_intervals.png'.\n"
     ]
    }
   ],
   "source": [
    "# response = await agent.achat(\"what is the auc_roc score of the trained model?\")\n",
    "# response = agent_model.query(\"what is the auc_roc score of the XGBoost model?\")\n",
    "# response = agent_model.query(\"what is the uncertainty quantification of the HGBoost model?\")\n",
    "response = agent_model.query(\"what is the prediction intervals for XGBoost model?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Agent Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods for running the agents / query pipelines\n",
    "def run_agent(query: str) -> str:\n",
    "    \"\"\"Run the agent model on the query to get evaluation results from trained model.\"\"\"\n",
    "    response = agent_model.query(query)\n",
    "    return str(response)\n",
    "\n",
    "def run_query_pipeline(query: str) -> str:\n",
    "    \"\"\"Run the query pipeline to analyze dataset for the given query.\"\"\"\n",
    "    response = qp_table.run(\n",
    "        query_str=query,\n",
    "    )\n",
    "    return str(response.message.content)\n",
    "\n",
    "# create tools\n",
    "run_agent_tool = FunctionTool.from_defaults(name=\"run_agent\", fn=run_agent)\n",
    "run_query_pipeline_tool = FunctionTool.from_defaults(name=\"run_query_pipeline\", fn=run_query_pipeline)\n",
    "agent_tools = [run_agent_tool, run_query_pipeline_tool]\n",
    "\n",
    "top_level_agent_prompt = \"\"\"\n",
    "                You are designed to help with a variety of tasks, from answering questions \\\n",
    "                to providing summaries to other types of analyses.\n",
    "\n",
    "                ## Tools\n",
    "                You have access to a wide variety of tools. You are responsible for using\n",
    "                the tools in any sequence you deem appropriate to complete the task at hand.\n",
    "                This may require breaking the task into subtasks and using different tools\n",
    "                to complete each subtask.\n",
    "\n",
    "                You have access to the following tools:\n",
    "                {tool_desc}\n",
    "\n",
    "                ## Output Format\n",
    "                To answer the question, please use the following format.\n",
    "\n",
    "                ```\n",
    "                Thought: I need to use a tool to help me answer the question.\n",
    "                Action: tool name (one of {tool_names}) if using a tool.\n",
    "                Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\n",
    "                ```\n",
    "\n",
    "                Please ALWAYS start with a Thought.\n",
    "\n",
    "                Please use a valid JSON format for the Action Input. Do NOT do this {{'input': 'hello world', 'num_beams': 5}}.\n",
    "\n",
    "                If this format is used, the user will respond in the following format:\n",
    "\n",
    "                ```\n",
    "                Observation: tool response\n",
    "                ```\n",
    "\n",
    "                You should keep repeating the above format until you have enough information\n",
    "                to answer the question without using any more tools. At that point, you MUST respond\n",
    "                in the one of the following two formats:\n",
    "\n",
    "                ```\n",
    "                Thought: I can answer without using any more tools.\n",
    "                Answer: [your answer here]\n",
    "                ```\n",
    "\n",
    "                ```\n",
    "                Thought: I cannot answer the question with the provided tools.\n",
    "                Answer: Sorry, I cannot answer your query.\n",
    "                ```\n",
    "\n",
    "                ## Additional Rules\n",
    "                - You MUST obey the function signature of each tool. Do NOT pass in no arguments if the function expects arguments.\n",
    "                - For queries that clearly involve data retrieval or manipulation (like 'analyze sales data', 'show trends in data'), use 'run_query_pipeline'.\n",
    "                - For queries that directly relate to model performance or evaluation (like 'what is the AUC_ROC score', 'evaluate the prediction accuracy'), use 'run_agent'.\n",
    "\n",
    "                ## Current Conversation\n",
    "                Below is the current conversation consisting of interleaving human and assistant messages.\n",
    "                \"\"\"\n",
    "top_level_agent_prompt = PromptTemplate(top_level_agent_prompt)\n",
    "agent = ReActAgent.from_tools(tools=agent_tools, \n",
    "                                    llm=llm, \n",
    "                                    verbose=True)\n",
    "agent.update_prompts({\"agent_worker:system_prompt\": top_level_agent_prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The user is asking for a specific count of positive cases, which involves data retrieval. I should use the 'run_query_pipeline' tool to answer this question.\n",
      "Action: run_query_pipeline\n",
      "Action Input: {'query': 'how many positive cases'}\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query_str: how many positive cases\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_prompt with input: \n",
      "query_str: how many positive cases\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm1 with input: \n",
      "messages: You are working with a pandas dataframe in Python.\n",
      "The name of the dataframe is `df`.\n",
      "This is the result of `print(df.head())`:\n",
      "  case_id  Target  age  max_activity_count  duration_since_reg  crp  \\\n",
      "0...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_output_parser with input: \n",
      "input: assistant: df['Target'].sum()\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_prompt with input: \n",
      "query_str: how many positive cases\n",
      "pandas_instructions: assistant: df['Target'].sum()\n",
      "pandas_output: 98\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm2 with input: \n",
      "messages: Given an input question, synthesize a response from the query results.\n",
      "Query: how many positive cases\n",
      "\n",
      "Pandas Instructions (optional):\n",
      "df['Target'].sum()\n",
      "\n",
      "Pandas Output: 98\n",
      "\n",
      "Response: \n",
      "\n",
      "\u001b[0m\u001b[1;3;34mObservation: Based on the data provided, there are 98 positive cases.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I have the answer to the user's question, so I can respond without using any more tools.\n",
      "Answer: There are 98 positive cases.\n",
      "\u001b[0mThere are 98 positive cases.\n"
     ]
    }
   ],
   "source": [
    "# response = await agent.achat(\"what is the auc_roc score of the trained model?\")\n",
    "# response = agent.query(\"what is the auc_roc score of the trained XGBoost model?\")\n",
    "response = agent.query(\"how many positive cases?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: agent_worker:system_prompt\n",
      "\n",
      "Value: \n",
      "                You are designed to help with a variety of tasks, from answering questions                 to providing summaries to other types of analyses.\n",
      "\n",
      "                ## Tools\n",
      "                You have access to a wide variety of tools. You are responsible for using\n",
      "                the tools in any sequence you deem appropriate to complete the task at hand.\n",
      "                This may require breaking the task into subtasks and using different tools\n",
      "                to complete each subtask.\n",
      "\n",
      "                You have access to the following tools:\n",
      "                {tool_desc}\n",
      "\n",
      "                ## Output Format\n",
      "                To answer the question, please use the following format.\n",
      "\n",
      "                ```\n",
      "                Thought: I need to use a tool to help me answer the question.\n",
      "                Action: tool name (one of {tool_names}) if using a tool.\n",
      "                Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\n",
      "                ```\n",
      "\n",
      "                Please ALWAYS start with a Thought.\n",
      "\n",
      "                Please use a valid JSON format for the Action Input. Do NOT do this {{'input': 'hello world', 'num_beams': 5}}.\n",
      "\n",
      "                If this format is used, the user will respond in the following format:\n",
      "\n",
      "                ```\n",
      "                Observation: tool response\n",
      "                ```\n",
      "\n",
      "                You should keep repeating the above format until you have enough information\n",
      "                to answer the question without using any more tools. At that point, you MUST respond\n",
      "                in the one of the following two formats:\n",
      "\n",
      "                ```\n",
      "                Thought: I can answer without using any more tools.\n",
      "                Answer: [your answer here]\n",
      "                ```\n",
      "\n",
      "                ```\n",
      "                Thought: I cannot answer the question with the provided tools.\n",
      "                Answer: Sorry, I cannot answer your query.\n",
      "                ```\n",
      "\n",
      "                ## Additional Rules\n",
      "                - You MUST obey the function signature of each tool. Do NOT pass in no arguments if the function expects arguments.\n",
      "                - For queries that clearly involve data retrieval or manipulation (like 'analyze sales data', 'show trends in data'), use 'run_query_pipeline'.\n",
      "                - For queries that directly relate to model performance or evaluation (like 'what is the AUC_ROC score', 'evaluate the prediction accuracy'), use 'run_agent'.\n",
      "\n",
      "                ## Current Conversation\n",
      "                Below is the current conversation consisting of interleaving human and assistant messages.\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "prompt_dict = agent.get_prompts()\n",
    "for k, v in prompt_dict.items():\n",
    "    print(f\"Prompt: {k}\\n\\nValue: {v.template}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Agent run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The user is asking for a count of positive cases, which involves data retrieval. I should use the 'run_query_pipeline' tool to answer this question.\n",
      "Action: run_query_pipeline\n",
      "Action Input: {'query': 'count positive cases'}\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query_str: count positive cases\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_prompt with input: \n",
      "query_str: count positive cases\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm1 with input: \n",
      "messages: You are working with a pandas dataframe in Python.\n",
      "The name of the dataframe is `df`.\n",
      "This is the result of `print(df.head())`:\n",
      "  case_id  Target  age  max_activity_count  duration_since_reg  crp  \\\n",
      "0...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_output_parser with input: \n",
      "input: assistant: df['Target'].sum()\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_prompt with input: \n",
      "query_str: count positive cases\n",
      "pandas_instructions: assistant: df['Target'].sum()\n",
      "pandas_output: 98\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm2 with input: \n",
      "messages: Given an input question, synthesize a response from the query results.\n",
      "Query: count positive cases\n",
      "\n",
      "Pandas Instructions (optional):\n",
      "df['Target'].sum()\n",
      "\n",
      "Pandas Output: 98\n",
      "\n",
      "Response: \n",
      "\n",
      "\u001b[0m\u001b[1;3;34mObservation: Based on the data provided, the total count of positive cases is 98.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I have the answer to the question, so I can provide it without using any more tools.\n",
      "Answer: There are 98 positive cases according to the data provided.\n",
      "\u001b[0m===========================final response============================\n",
      "There are 98 positive cases according to the data provided.\n"
     ]
    }
   ],
   "source": [
    "# response = await agent.achat(\"what is the auc_roc score of the trained model?\")\n",
    "response = agent.query(\"how many positive cases?\")\n",
    "print(f'===========================final response============================\\n{str(response)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: This question involves model performance evaluation, specifically asking for the AUC_ROC score of the trained XGBoost model. I should use the 'run_agent' tool to answer this.\n",
      "Action: run_agent\n",
      "Action Input: {'query': 'auc_roc_score_xgboost'}\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: The current language of the user is: English. The user is asking about the AUC ROC score for the XGBoost model. I need to use the 'evaluate_model' tool to help me answer this question.\n",
      "Action: evaluate_model\n",
      "Action Input: {'model_name': 'xgboost'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: {'roc_auc': 0.8659217877094972, 'average_precision': 0.7481294952146433, 'mcc': 0.7002038117109098, 'f1_macro': 0.8472989564149784, 'confusion_matrix': array([[176,   3],\n",
      "       [  7,  13]], dtype=int64)}\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: The current language of the user is: English. I have the results of the XGBoost model evaluation. The AUC ROC score is 0.8659217877094972.\n",
      "Answer: The AUC ROC score for the XGBoost model is 0.8659217877094972.\n",
      "\u001b[0m\u001b[1;3;34mObservation: The AUC ROC score for the XGBoost model is 0.8659217877094972.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I have received the AUC_ROC score for the XGBoost model from the 'run_agent' tool.\n",
      "Answer: The AUC_ROC score for the XGBoost model is 0.8659217877094972.\n",
      "\u001b[0m===========================final response============================\n",
      "The AUC_ROC score for the XGBoost model is 0.8659217877094972.\n"
     ]
    }
   ],
   "source": [
    "# response = await agent.achat(\"what is the auc_roc score of the trained model?\")\n",
    "response = agent.query(\"what is the auc_roc score of the trained XGBoost model?\")\n",
    "print(f'===========================final response============================\\n{str(response)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: This question involves data retrieval and manipulation, specifically calculating the average time patients spend in the hospital. I should use the 'run_query_pipeline' tool to analyze the dataset and find this information.\n",
      "Action: run_query_pipeline\n",
      "Action Input: {'query': 'average time patients spend in the hospital'}\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query_str: average time patients spend in the hospital\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_prompt with input: \n",
      "query_str: average time patients spend in the hospital\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm1 with input: \n",
      "messages: You are working with a pandas dataframe in Python.\n",
      "The name of the dataframe is `df`.\n",
      "This is the result of `print(df.head())`:\n",
      "  case_id  Target  age  max_activity_count  duration_since_reg  crp  \\\n",
      "0...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_output_parser with input: \n",
      "input: assistant: df['duration_since_reg'].mean()\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_prompt with input: \n",
      "query_str: average time patients spend in the hospital\n",
      "pandas_instructions: assistant: df['duration_since_reg'].mean()\n",
      "pandas_output: 11.568710217755443\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm2 with input: \n",
      "messages: Given an input question, synthesize a response from the query results.\n",
      "Query: average time patients spend in the hospital\n",
      "\n",
      "Pandas Instructions (optional):\n",
      "df['duration_since_reg'].mean()\n",
      "\n",
      "Pandas Outpu...\n",
      "\n",
      "\u001b[0m\u001b[1;3;34mObservation: Based on the data provided, the average time patients spend in the hospital is approximately 11.57 days.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I have received the result from the 'run_query_pipeline' tool, which calculated the average time patients spend in the hospital. Now I can answer the question without using any more tools.\n",
      "Answer: The average time patients spend in the hospital is approximately 11.57 days.\n",
      "\u001b[0m===========================final response============================\n",
      "The average time patients spend in the hospital is approximately 11.57 days.\n"
     ]
    }
   ],
   "source": [
    "# response = await agent.achat(\"what is the auc_roc score of the trained model?\")\n",
    "response = agent.query(\"what is the average time patients spend in the hospital?\")\n",
    "print(f'===========================final response============================\\n{str(response)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
