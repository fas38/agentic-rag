{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda_envs\\rag\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import List,Optional\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# llama index imports\n",
    "from llama_index.core import SimpleDirectoryReader,VectorStoreIndex,SummaryIndex, StorageContext, Settings, load_index_from_storage\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core.node_parser import SentenceSplitter, CodeSplitter, LangchainNodeParser\n",
    "from llama_index.core.tools import FunctionTool,QueryEngineTool\n",
    "from llama_index.core.vector_stores import MetadataFilters,FilterCondition\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "from llama_index.readers.file import IPYNBReader, PandasCSVReader\n",
    "from llama_index.experimental.query_engine import PandasQueryEngine\n",
    "from llama_index.experimental.query_engine.pandas import (\n",
    "    PandasInstructionParser,\n",
    ")\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.query_pipeline import (\n",
    "    QueryPipeline as QP,\n",
    "    Link,\n",
    "    InputComponent,\n",
    ")\n",
    "\n",
    "# llama index agent imports\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker, ReActAgent\n",
    "from llama_index.core.agent import AgentRunner\n",
    "\n",
    "# llama index llms and embeddings imports\n",
    "from llama_index.llms.mistralai import MistralAI\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.mistralai import MistralAIEmbedding\n",
    "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# custom package imports\n",
    "from llama_index.packs.tables.chain_of_table.base import ChainOfTableQueryEngine, serialize_table\n",
    "\n",
    "# langchain imports\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
    "\n",
    "# tools\n",
    "import nest_asyncio # to allow running async functions in jupyter\n",
    "import chromadb # persistent storage for vectors\n",
    "# import nbconvert\n",
    "import tree_sitter\n",
    "import tree_sitter_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply() # to allow running async functions in jupyter\n",
    "\n",
    "# setting flags\n",
    "create_index = True\n",
    "\n",
    "# configuration\n",
    "MISTRAL_API_KEY =  \"BWdlihu9sUh5P2g3bHnzjAaHiT4anTVH\"\n",
    "embedding = \"BAAI/bge-small-en-v1.5\"\n",
    "# embedding = \"Qdrant/bm42-all-minilm-l6-v2-attentions\"\n",
    "# embedding = \"mistral-embed\"\n",
    "# embedding = OllamaEmbedding(\n",
    "#     model_name=\"llama2\",\n",
    "#     base_url=\"http://localhost:11434\",\n",
    "#     ollama_additional_kwargs={\"mirostat\": 0} \n",
    "# )\n",
    "# embedding = \"Salesforce/codet5p-110m-embedding\"\n",
    "llm_model = \"mistral-large-latest\"\n",
    "# llm_model = \"codellama\"\n",
    "chunk_size = 2000 # number of lines\n",
    "chunk_overlap = 200 # number of lines to overlap between chunks\n",
    "language = \"python\"\n",
    "data_path = \"./data_python\"\n",
    "\n",
    "# setup the llm and embedding\n",
    "embed_model = FastEmbedEmbedding(model_name=embedding)\n",
    "# embed_model = MistralAIEmbedding(model_name=embedding, api_key=MISTRAL_API_KEY)\n",
    "# embed_model =  HuggingFaceEmbedding(model_name=embedding)  \n",
    "Settings.embed_model = embed_model\n",
    "Settings.chunk_size = chunk_size\n",
    "Settings.chunk_overlap = chunk_overlap\n",
    "os.environ[\"MISTRAL_API_KEY\"] = MISTRAL_API_KEY\n",
    "llm = MistralAI(model=llm_model, temperature=0.0)\n",
    "# llm = Ollama(model=llm_model, request_timeout=1200.0, base_url=\"http://localhost:11434\", temperature=0.0)\n",
    "# temperture = 0.0 for deterministic results\n",
    "Settings.llm = llm\n",
    "\n",
    "# setup the persistent storage for vector store\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db_mistral_python\")\n",
    "chroma_collection = db.get_or_create_collection(\"code-agent\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for investigating node outputs\n",
    "\n",
    "# #load documents\n",
    "# file_path = \"./data_python/tabular_classification_binary.ipynb\"\n",
    "# documents = SimpleDirectoryReader(input_files = [file_path]).load_data()\n",
    "# print(f\"length of nodes\")\n",
    "# # splitter = CodeSplitter(language=\"python\", chunk_lines=chunk_size, chunk_lines_overlap=chunk_overlap, max_chars=max_chars)\n",
    "# splitter = LangchainNodeParser(RecursiveCharacterTextSplitter().from_language(Language.PYTHON, chunk_size=2000, chunk_overlap=0))\n",
    "# nodes = splitter.get_nodes_from_documents(documents)\n",
    "# print(f\"Length of nodes : {len(nodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for setting vector and summary tool from a document by creating new vector and summary index\n",
    "def get_doc_tools(file_path:str, name:str) -> str:\n",
    "  \"\"\"Get vector query and summary query tools from a jupyter notebook.\"\"\"\n",
    "  \n",
    "  #load documents\n",
    "  documents = SimpleDirectoryReader(input_files = [file_path]).load_data()\n",
    "  print(f\"length of nodes\")\n",
    "  # splitter = CodeSplitter(language=\"python\", chunk_lines=chunk_size, chunk_lines_overlap=chunk_overlap, max_chars=max_chars)\n",
    "  splitter = LangchainNodeParser(RecursiveCharacterTextSplitter().from_language(Language.PYTHON, chunk_size=chunk_size, chunk_overlap=chunk_overlap))\n",
    "  nodes = splitter.get_nodes_from_documents(documents)\n",
    "  print(f\"Length of nodes : {len(nodes)}\")\n",
    "  \n",
    "  #instantiate Vector store\n",
    "  vector_index = VectorStoreIndex(nodes,storage_context=storage_context)\n",
    "  vector_index.storage_context.vector_store.persist(persist_path=\"/content/chroma_db\")\n",
    "  \n",
    "  # Vector store Auto retrieval query engine method\n",
    "  def vector_query(query:str) -> str:\n",
    "    \"\"\"\n",
    "    query (str): the string query to be embedded\n",
    "    \"\"\"\n",
    "    query_engine = vector_index.as_query_engine(similarity_top_k =2) # set vector query engine with similarity as top 2 results\n",
    "    \n",
    "    response = query_engine.query(query)\n",
    "    return response\n",
    "  \n",
    "  # Prepare Vector Tool\n",
    "  vector_query_tool = FunctionTool.from_defaults(name=f\"vector_tool_{name}\", fn=vector_query)\n",
    "  \n",
    "  # Prepare Summary Tool\n",
    "  summary_index = SummaryIndex(nodes)\n",
    "  summary_index.storage_context.persist(persist_dir=\"./db_mistral_python\") # save the summary index to disk\n",
    "  summary_query_engine = summary_index.as_query_engine(response_mode=\"tree_summarize\", use_async=True) # set summary query engine with tree summarization\n",
    "  summary_query_tool = QueryEngineTool.from_defaults(name=f\"summary_tool_{name}\",query_engine=summary_query_engine, description=(\"Use ONLY IF you want to get a holistic approach for full implementation\" \"DO NOT USE if you have question for specific implementation.\")) # set summary query tool with prompt\n",
    "  return vector_query_tool,summary_query_tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for setting vector and summary tool from a document by loading vector and summary index from storage\n",
    "def get_doc_tools_from_storage(file_path:str, name:str) -> str:\n",
    "  \"\"\"Get vector query and summary query tools from a document.\"\"\"\n",
    "  \n",
    "  #load vector store\n",
    "  vector_index = VectorStoreIndex.from_vector_store(vector_store=vector_store, storage_context=storage_context)\n",
    "  \n",
    "  # Vector store Auto retrieval query engine method\n",
    "  def vector_query(query:str, page_numbers:Optional[List[str]] = None) -> str:\n",
    "    \"\"\"\n",
    "    query (str): the string query to be embedded\n",
    "    page_numbers Optional[List[str]]: List of page numbers to be retrieved.\n",
    "    Leave as NONE if we want to perform a vector search over all pages. \n",
    "    Otherwise, filter by the set of specified pages.\n",
    "    Always leave page_numbers as None UNLESS there is a specific page you want to search for.\n",
    "    \"\"\"\n",
    "    page_numbers = page_numbers or []\n",
    "    metadata_dict = [{\"key\":'page_label', \"value\":p} for p in page_numbers]\n",
    "    \n",
    "    query_engine = vector_index.as_query_engine(similarity_top_k =2, filters = MetadataFilters.from_dicts(metadata_dict, condition=FilterCondition.OR)) # set vector query engine with similarity as top 2 results\n",
    "    \n",
    "    response = query_engine.query(query)\n",
    "    return response\n",
    "  \n",
    "  # Prepare Vector Tool\n",
    "  vector_query_tool = FunctionTool.from_defaults(name=f\"vector_tool_{name}\", fn=vector_query)\n",
    "  \n",
    "  # Prepare Summary Tool\n",
    "  storage_context_all = StorageContext.from_defaults(persist_dir=\"./db_mistral_python\") # set storage context for summary index\n",
    "  summary_index = load_index_from_storage(storage_context=storage_context_all) # load summary index from storage\n",
    "  summary_query_engine = summary_index.as_query_engine(response_mode=\"tree_summarize\", use_async=True) # set summary query engine with tree summarization\n",
    "  summary_query_tool = QueryEngineTool.from_defaults(name=f\"summary_tool_{name}\",query_engine=summary_query_engine, description=(\"Use ONLY IF you want to get a holistic summary of the documents.\" \"DO NOT USE if you have specified questions over the documents.\")) # set summary query tool with prompt\n",
    "  return vector_query_tool,summary_query_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of vector and summary tools for all documents in the path\n",
    "def get_doc_tools_from_path(path:str) -> list:\n",
    "  file_name = []\n",
    "  file_path = []\n",
    "  for file in os.listdir(path):\n",
    "    if file.endswith(\".ipynb\"):\n",
    "      file_name.append(file.split(\".\")[0])\n",
    "      file_path.append(os.path.join(path,file))\n",
    "\n",
    "  papers_to_tools_dict = {}\n",
    "  for name,filename in zip(file_name,file_path):\n",
    "    if create_index:\n",
    "      vector_query_tool,summary_query_tool = get_doc_tools(filename,name)\n",
    "    else:\n",
    "      vector_query_tool,summary_query_tool = get_doc_tools_from_storage(filename,name)\n",
    "    papers_to_tools_dict[name] = [vector_query_tool,summary_query_tool]\n",
    "\n",
    "  initial_tools = [t for f in file_name for t in papers_to_tools_dict[f]]\n",
    "  return initial_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of nodes\n",
      "Length of nodes : 132\n"
     ]
    }
   ],
   "source": [
    "# create object index from the list of tools\n",
    "initial_tools_for_data = get_doc_tools_from_path(data_path)\n",
    "obj_index = ObjectIndex.from_objects(initial_tools_for_data, index_cls=VectorStoreIndex)\n",
    "obj_retriever = obj_index.as_retriever(similarity_top_k=2) # set object retriever with similarity as top 2 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # setup single agent\n",
    "# agent_worker = FunctionCallingAgentWorker.from_tools(tool_retriever=obj_retriever, \n",
    "#                                                      llm=llm, \n",
    "#                                                      system_prompt=\"\"\"You are an agent designed to answer queries over a given jupyter notebook. Please always use the tools provided to answer a question.Do not rely on prior knowledge.\"\"\", \n",
    "#                                                      verbose=True) \n",
    "# agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup ReAct agent\n",
    "agent = ReActAgent.from_tools(tool_retriever=obj_retriever, \n",
    "                                     llm=llm, \n",
    "                                     system_prompt=\"\"\"You are a proficient python developer. Respond with the syntactically correct code for the question below. Make sure you follow these rules:\n",
    "                                        1. Use context to understand the APIs and how to use them.\n",
    "                                        2. Ensure all the requirements in the question are met.\n",
    "                                        3. Ensure the output code syntax is correct.\n",
    "                                        4. All required dependencies should be imported above the code.\n",
    "                                        Question:\n",
    "                                        {question}\n",
    "                                        Context:\n",
    "                                        {context}\n",
    "                                        Helpful Response:\"\"\", \n",
    "                                     verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using CodeLlama (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The current language of the user is English. I need to use a tool to help me answer the question.\n",
      "Action: vector_tool_tabular_classification_binary\n",
      "Action Input: {'query': 'how to train xgboost model for sepsis dataset?'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: To train an XGBoost model for the Sepsis dataset using the provided code, you can follow these steps:\n",
      "\n",
      "1. Import the necessary libraries:\n",
      "```python\n",
      "import pandas as pd\n",
      "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
      "from xgboost import XGBClassifier\n",
      "```\n",
      "2. Load the Sepsis dataset and split it into training and testing sets:\n",
      "```python\n",
      "# load the Sepsis dataset\n",
      "dataset = pd.read_csv(\"./dataset/Sepsis_Processed_IC.csv\")\n",
      "\n",
      "# split the data into training and testing sets\n",
      "train_data, test_data = dataset.split(test_size=0.2, random_state=42)\n",
      "```\n",
      "3. Preprocess the data:\n",
      "```python\n",
      "# labels and features separation\n",
      "X = train_data.drop(columns=['Target'], axis=1)\n",
      "y = train_data['Target']\n",
      "\n",
      "# one hot encoding the category columns\n",
      "category_columns = X.select_dtypes(include=['object']).columns\n",
      "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
      "X_encoded = one_hot_encoder.fit_transform(X[category_columns])\n",
      "X_encoded = pd.DataFrame(X_encoded, columns=one_hot_encoder.get_feature_names_out(category_columns))\n",
      "X = pd.concat([X, X_encoded], axis=1)\n",
      "X.drop(columns=category_columns, inplace=True)\n",
      "\n",
      "# convert bool to int\n",
      "bool_columns = X.select_dtypes(include=['bool']).columns\n",
      "for column in bool_columns:\n",
      "    X[column] = X[column].astype('int')\n",
      "\n",
      "# standardize the data using robust scaler\n",
      "scaler = RobustScaler()\n",
      "scaled_columns = ['age', 'max_activity_count', 'duration_since_reg', 'crp', 'lacticacid', 'hours_past_midnight', 'duration_last_event']\n",
      "X[scaled_columns] = scaler.fit_transform(X[scaled_columns])\n",
      "```\n",
      "4. Train the XGBoost model:\n",
      "```python\n",
      "# train the XGBoost model\n",
      "model = XGBClassifier()\n",
      "model.fit(X, y)\n",
      "```\n",
      "5. Evaluate the model on the testing data:\n",
      "```python\n",
      "# evaluate the model on the testing data\n",
      "y_pred = model.predict(test_data)\n",
      "accuracy = accuracy_score(test_data['Target'], y_pred)\n",
      "print(\"Accuracy:\", accuracy)\n",
      "```\n",
      "Note that this is just a basic example of how to train an XGBoost model for the Sepsis dataset using the provided code. You may need to adjust the preprocessing steps and the hyperparameters of the model based on your specific use case.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: To train an XGBoost model for the Sepsis dataset, you can follow these steps:\n",
      "\n",
      "1. Import the necessary libraries:\n",
      "```python\n",
      "import pandas as pd\n",
      "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
      "from xgboost import XGBClassifier\n",
      "```\n",
      "2. Load the Sepsis dataset and split it into training and testing sets:\n",
      "```python\n",
      "# load the Sepsis dataset\n",
      "dataset = pd.read_csv(\"./dataset/Sepsis_Processed_IC.csv\")\n",
      "\n",
      "# split the data into training and testing sets\n",
      "train_data, test_data = dataset.split(test_size=0.2, random_state=42)\n",
      "```\n",
      "3. Preprocess the data:\n",
      "```python\n",
      "# labels and features separation\n",
      "X = train_data.drop(columns=['Target'], axis=1)\n",
      "y = train_data['Target']\n",
      "\n",
      "# one hot encoding the category columns\n",
      "category_columns = X.select_dtypes(include=['object']).columns\n",
      "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
      "X_encoded = one_hot_encoder.fit_transform(X[category_columns])\n",
      "X_encoded = pd.DataFrame(X_encoded, columns=one_hot_encoder.get_feature_names_out(category_columns))\n",
      "X = pd.concat([X, X_encoded], axis=1)\n",
      "X.drop(columns=category_columns, inplace=True)\n",
      "\n",
      "# convert bool to int\n",
      "bool_columns = X.select_dtypes(include=['bool']).columns\n",
      "for column in bool_columns:\n",
      "    X[column] = X[column].astype('int')\n",
      "\n",
      "# standardize the data using robust scaler\n",
      "scaler = RobustScaler()\n",
      "scaled_columns = ['age', 'max_activity_count', 'duration_since_reg', 'crp', 'lacticacid', 'hours_past_midnight', 'duration_last_event']\n",
      "X[scaled_columns] = scaler.fit_transform(X[scaled_columns])\n",
      "```\n",
      "4. Train the XGBoost model:\n",
      "```python\n",
      "# train the XGBoost model\n",
      "model = XGBClassifier()\n",
      "model.fit(X, y)\n",
      "```\n",
      "5. Evaluate the model on the testing data:\n",
      "```python\n",
      "# evaluate the model on the testing data\n",
      "y_pred = model.predict(test_data)\n",
      "accuracy = accuracy_score(test_data['Target'], y_pred)\n",
      "print(\"Accuracy:\", accuracy)\n",
      "```\n",
      "Note that this is just a basic example of how to train an XGBoost model for the Sepsis dataset using the provided code. You may need to adjust the preprocessing steps and the hyperparameters of the model based on your specific use case.\n",
      "\u001b[0mTo train an XGBoost model for the Sepsis dataset, you can follow these steps:\n",
      "\n",
      "1. Import the necessary libraries:\n",
      "```python\n",
      "import pandas as pd\n",
      "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
      "from xgboost import XGBClassifier\n",
      "```\n",
      "2. Load the Sepsis dataset and split it into training and testing sets:\n",
      "```python\n",
      "# load the Sepsis dataset\n",
      "dataset = pd.read_csv(\"./dataset/Sepsis_Processed_IC.csv\")\n",
      "\n",
      "# split the data into training and testing sets\n",
      "train_data, test_data = dataset.split(test_size=0.2, random_state=42)\n",
      "```\n",
      "3. Preprocess the data:\n",
      "```python\n",
      "# labels and features separation\n",
      "X = train_data.drop(columns=['Target'], axis=1)\n",
      "y = train_data['Target']\n",
      "\n",
      "# one hot encoding the category columns\n",
      "category_columns = X.select_dtypes(include=['object']).columns\n",
      "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
      "X_encoded = one_hot_encoder.fit_transform(X[category_columns])\n",
      "X_encoded = pd.DataFrame(X_encoded, columns=one_hot_encoder.get_feature_names_out(category_columns))\n",
      "X = pd.concat([X, X_encoded], axis=1)\n",
      "X.drop(columns=category_columns, inplace=True)\n",
      "\n",
      "# convert bool to int\n",
      "bool_columns = X.select_dtypes(include=['bool']).columns\n",
      "for column in bool_columns:\n",
      "    X[column] = X[column].astype('int')\n",
      "\n",
      "# standardize the data using robust scaler\n",
      "scaler = RobustScaler()\n",
      "scaled_columns = ['age', 'max_activity_count', 'duration_since_reg', 'crp', 'lacticacid', 'hours_past_midnight', 'duration_last_event']\n",
      "X[scaled_columns] = scaler.fit_transform(X[scaled_columns])\n",
      "```\n",
      "4. Train the XGBoost model:\n",
      "```python\n",
      "# train the XGBoost model\n",
      "model = XGBClassifier()\n",
      "model.fit(X, y)\n",
      "```\n",
      "5. Evaluate the model on the testing data:\n",
      "```python\n",
      "# evaluate the model on the testing data\n",
      "y_pred = model.predict(test_data)\n",
      "accuracy = accuracy_score(test_data['Target'], y_pred)\n",
      "print(\"Accuracy:\", accuracy)\n",
      "```\n",
      "Note that this is just a basic example of how to train an XGBoost model for the Sepsis dataset using the provided code. You may need to adjust the preprocessing steps and the hyperparameters of the model based on your specific use case.\n"
     ]
    }
   ],
   "source": [
    "response = await agent.achat(\"how to train xgboost model for sepsis dataset?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActionReasoningStep -> thought='The current language of the user is English. I need to use a tool to help me answer the question.' action='vector_tool_tabular_classification_binary' action_input={'query': 'how to train xgboost model for sepsis dataset?'}\n",
      "\n",
      "ObservationReasoningStep -> observation='To train an XGBoost model for the Sepsis dataset using the provided code, you can follow these steps:\\n\\n1. Import the necessary libraries:\\n```python\\nimport pandas as pd\\nfrom sklearn.preprocessing import OneHotEncoder, RobustScaler\\nfrom xgboost import XGBClassifier\\n```\\n2. Load the Sepsis dataset and split it into training and testing sets:\\n```python\\n# load the Sepsis dataset\\ndataset = pd.read_csv(\"./dataset/Sepsis_Processed_IC.csv\")\\n\\n# split the data into training and testing sets\\ntrain_data, test_data = dataset.split(test_size=0.2, random_state=42)\\n```\\n3. Preprocess the data:\\n```python\\n# labels and features separation\\nX = train_data.drop(columns=[\\'Target\\'], axis=1)\\ny = train_data[\\'Target\\']\\n\\n# one hot encoding the category columns\\ncategory_columns = X.select_dtypes(include=[\\'object\\']).columns\\none_hot_encoder = OneHotEncoder(sparse_output=False)\\nX_encoded = one_hot_encoder.fit_transform(X[category_columns])\\nX_encoded = pd.DataFrame(X_encoded, columns=one_hot_encoder.get_feature_names_out(category_columns))\\nX = pd.concat([X, X_encoded], axis=1)\\nX.drop(columns=category_columns, inplace=True)\\n\\n# convert bool to int\\nbool_columns = X.select_dtypes(include=[\\'bool\\']).columns\\nfor column in bool_columns:\\n    X[column] = X[column].astype(\\'int\\')\\n\\n# standardize the data using robust scaler\\nscaler = RobustScaler()\\nscaled_columns = [\\'age\\', \\'max_activity_count\\', \\'duration_since_reg\\', \\'crp\\', \\'lacticacid\\', \\'hours_past_midnight\\', \\'duration_last_event\\']\\nX[scaled_columns] = scaler.fit_transform(X[scaled_columns])\\n```\\n4. Train the XGBoost model:\\n```python\\n# train the XGBoost model\\nmodel = XGBClassifier()\\nmodel.fit(X, y)\\n```\\n5. Evaluate the model on the testing data:\\n```python\\n# evaluate the model on the testing data\\ny_pred = model.predict(test_data)\\naccuracy = accuracy_score(test_data[\\'Target\\'], y_pred)\\nprint(\"Accuracy:\", accuracy)\\n```\\nNote that this is just a basic example of how to train an XGBoost model for the Sepsis dataset using the provided code. You may need to adjust the preprocessing steps and the hyperparameters of the model based on your specific use case.' return_direct=False\n",
      "\n",
      "ResponseReasoningStep -> thought=\"I can answer without using any more tools. I'll use the user's language to answer.\" response='To train an XGBoost model for the Sepsis dataset, you can follow these steps:\\n\\n1. Import the necessary libraries:\\n```python\\nimport pandas as pd\\nfrom sklearn.preprocessing import OneHotEncoder, RobustScaler\\nfrom xgboost import XGBClassifier\\n```\\n2. Load the Sepsis dataset and split it into training and testing sets:\\n```python\\n# load the Sepsis dataset\\ndataset = pd.read_csv(\"./dataset/Sepsis_Processed_IC.csv\")\\n\\n# split the data into training and testing sets\\ntrain_data, test_data = dataset.split(test_size=0.2, random_state=42)\\n```\\n3. Preprocess the data:\\n```python\\n# labels and features separation\\nX = train_data.drop(columns=[\\'Target\\'], axis=1)\\ny = train_data[\\'Target\\']\\n\\n# one hot encoding the category columns\\ncategory_columns = X.select_dtypes(include=[\\'object\\']).columns\\none_hot_encoder = OneHotEncoder(sparse_output=False)\\nX_encoded = one_hot_encoder.fit_transform(X[category_columns])\\nX_encoded = pd.DataFrame(X_encoded, columns=one_hot_encoder.get_feature_names_out(category_columns))\\nX = pd.concat([X, X_encoded], axis=1)\\nX.drop(columns=category_columns, inplace=True)\\n\\n# convert bool to int\\nbool_columns = X.select_dtypes(include=[\\'bool\\']).columns\\nfor column in bool_columns:\\n    X[column] = X[column].astype(\\'int\\')\\n\\n# standardize the data using robust scaler\\nscaler = RobustScaler()\\nscaled_columns = [\\'age\\', \\'max_activity_count\\', \\'duration_since_reg\\', \\'crp\\', \\'lacticacid\\', \\'hours_past_midnight\\', \\'duration_last_event\\']\\nX[scaled_columns] = scaler.fit_transform(X[scaled_columns])\\n```\\n4. Train the XGBoost model:\\n```python\\n# train the XGBoost model\\nmodel = XGBClassifier()\\nmodel.fit(X, y)\\n```\\n5. Evaluate the model on the testing data:\\n```python\\n# evaluate the model on the testing data\\ny_pred = model.predict(test_data)\\naccuracy = accuracy_score(test_data[\\'Target\\'], y_pred)\\nprint(\"Accuracy:\", accuracy)\\n```\\nNote that this is just a basic example of how to train an XGBoost model for the Sepsis dataset using the provided code. You may need to adjust the preprocessing steps and the hyperparameters of the model based on your specific use case.' is_streaming=False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for resoning_step in agent.get_completed_tasks()[0].extra_state[\"current_reasoning\"]:\n",
    "    print(f\"{resoning_step.__class__.__name__} -> {resoning_step}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To train an XGBoost model for the Sepsis dataset, you can follow these steps:\n",
      "\n",
      "1. Import the necessary libraries:\n",
      "```python\n",
      "import pandas as pd\n",
      "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
      "from xgboost import XGBClassifier\n",
      "```\n",
      "2. Load the Sepsis dataset and split it into training and testing sets:\n",
      "```python\n",
      "# load the Sepsis dataset\n",
      "dataset = pd.read_csv(\"./dataset/Sepsis_Processed_IC.csv\")\n",
      "\n",
      "# split the data into training and testing sets\n",
      "train_data, test_data = dataset.split(test_size=0.2, random_state=42)\n",
      "```\n",
      "3. Preprocess the data:\n",
      "```python\n",
      "# labels and features separation\n",
      "X = train_data.drop(columns=['Target'], axis=1)\n",
      "y = train_data['Target']\n",
      "\n",
      "# one hot encoding the category columns\n",
      "category_columns = X.select_dtypes(include=['object']).columns\n",
      "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
      "X_encoded = one_hot_encoder.fit_transform(X[category_columns])\n",
      "X_encoded = pd.DataFrame(X_encoded, columns=one_hot_encoder.get_feature_names_out(category_columns))\n",
      "X = pd.concat([X, X_encoded], axis=1)\n",
      "X.drop(columns=category_columns, inplace=True)\n",
      "\n",
      "# convert bool to int\n",
      "bool_columns = X.select_dtypes(include=['bool']).columns\n",
      "for column in bool_columns:\n",
      "    X[column] = X[column].astype('int')\n",
      "\n",
      "# standardize the data using robust scaler\n",
      "scaler = RobustScaler()\n",
      "scaled_columns = ['age', 'max_activity_count', 'duration_since_reg', 'crp', 'lacticacid', 'hours_past_midnight', 'duration_last_event']\n",
      "X[scaled_columns] = scaler.fit_transform(X[scaled_columns])\n",
      "```\n",
      "4. Train the XGBoost model:\n",
      "```python\n",
      "# train the XGBoost model\n",
      "model = XGBClassifier()\n",
      "model.fit(X, y)\n",
      "```\n",
      "5. Evaluate the model on the testing data:\n",
      "```python\n",
      "# evaluate the model on the testing data\n",
      "y_pred = model.predict(test_data)\n",
      "accuracy = accuracy_score(test_data['Target'], y_pred)\n",
      "print(\"Accuracy:\", accuracy)\n",
      "```\n",
      "Note that this is just a basic example of how to train an XGBoost model for the Sepsis dataset using the provided code. You may need to adjust the preprocessing steps and the hyperparameters of the model based on your specific use case.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: (Implicit) I can answer without any more tools!\n",
      "Answer: To compute conformal predictions manually on a trained XGBoost model, you can follow these steps:\n",
      "\n",
      "1. Load the trained XGBoost model and the testing data:\n",
      "```python\n",
      "import xgboost as xgb\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "# load the trained XGBoost model\n",
      "model = xgb.XGBClassifier()\n",
      "model.load_model(\"./models/xgb_model.json\")\n",
      "\n",
      "# load the testing data\n",
      "test_data = pd.read_csv(\"./dataset/Sepsis_Processed_IC.csv\")\n",
      "```\n",
      "2. Preprocess the testing data:\n",
      "```python\n",
      "# labels and features separation\n",
      "X = test_data.drop(columns=['Target'], axis=1)\n",
      "y = test_data['Target']\n",
      "\n",
      "# one hot encoding the category columns\n",
      "category_columns = X.select_dtypes(include=['object']).columns\n",
      "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
      "X_encoded = one_hot_encoder.fit_transform(X[category_columns])\n",
      "X_encoded = pd.DataFrame(X_encoded, columns=one_hot_encoder.get_feature_names_out(category_columns))\n",
      "X = pd.concat([X, X_encoded], axis=1)\n",
      "X.drop(columns=category_columns, inplace=True)\n",
      "\n",
      "# convert bool to int\n",
      "bool_columns = X.select_dtypes(include=['bool']).columns\n",
      "for column in bool_columns:\n",
      "    X[column] = X[column].astype('int')\n",
      "\n",
      "# standardize the data using robust scaler\n",
      "scaler = RobustScaler()\n",
      "scaled_columns = ['age', 'max_activity_count', 'duration_since_reg', 'crp', 'lacticacid', 'hours_past_midnight', 'duration_last_event']\n",
      "X[scaled_columns] = scaler.fit_transform(X[scaled_columns])\n",
      "```\n",
      "3. Compute the conformal predictions:\n",
      "```python\n",
      "# compute the conformal predictions\n",
      "conformal_predictions = model.predict(X)\n",
      "confidence_scores = model.predict_proba(X)[:, 1]\n",
      "```\n",
      "4. Evaluate the conformal predictions:\n",
      "```python\n",
      "# evaluate the conformal predictions\n",
      "accuracy = accuracy_score(y, conformal_predictions)\n",
      "print(\"Accuracy:\", accuracy)\n",
      "```\n",
      "Note that this is just a basic example of how to compute conformal predictions manually on an XGBoost model using the provided code. You may need to adjust the preprocessing steps and the hyperparameters of the model based on your specific use case.\n",
      "\u001b[0mTo compute conformal predictions manually on a trained XGBoost model, you can follow these steps:\n",
      "\n",
      "1. Load the trained XGBoost model and the testing data:\n",
      "```python\n",
      "import xgboost as xgb\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "# load the trained XGBoost model\n",
      "model = xgb.XGBClassifier()\n",
      "model.load_model(\"./models/xgb_model.json\")\n",
      "\n",
      "# load the testing data\n",
      "test_data = pd.read_csv(\"./dataset/Sepsis_Processed_IC.csv\")\n",
      "```\n",
      "2. Preprocess the testing data:\n",
      "```python\n",
      "# labels and features separation\n",
      "X = test_data.drop(columns=['Target'], axis=1)\n",
      "y = test_data['Target']\n",
      "\n",
      "# one hot encoding the category columns\n",
      "category_columns = X.select_dtypes(include=['object']).columns\n",
      "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
      "X_encoded = one_hot_encoder.fit_transform(X[category_columns])\n",
      "X_encoded = pd.DataFrame(X_encoded, columns=one_hot_encoder.get_feature_names_out(category_columns))\n",
      "X = pd.concat([X, X_encoded], axis=1)\n",
      "X.drop(columns=category_columns, inplace=True)\n",
      "\n",
      "# convert bool to int\n",
      "bool_columns = X.select_dtypes(include=['bool']).columns\n",
      "for column in bool_columns:\n",
      "    X[column] = X[column].astype('int')\n",
      "\n",
      "# standardize the data using robust scaler\n",
      "scaler = RobustScaler()\n",
      "scaled_columns = ['age', 'max_activity_count', 'duration_since_reg', 'crp', 'lacticacid', 'hours_past_midnight', 'duration_last_event']\n",
      "X[scaled_columns] = scaler.fit_transform(X[scaled_columns])\n",
      "```\n",
      "3. Compute the conformal predictions:\n",
      "```python\n",
      "# compute the conformal predictions\n",
      "conformal_predictions = model.predict(X)\n",
      "confidence_scores = model.predict_proba(X)[:, 1]\n",
      "```\n",
      "4. Evaluate the conformal predictions:\n",
      "```python\n",
      "# evaluate the conformal predictions\n",
      "accuracy = accuracy_score(y, conformal_predictions)\n",
      "print(\"Accuracy:\", accuracy)\n",
      "```\n",
      "Note that this is just a basic example of how to compute conformal predictions manually on an XGBoost model using the provided code. You may need to adjust the preprocessing steps and the hyperparameters of the model based on your specific use case.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"give me the code for computing conformal prediction manually on the trained model\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To compute conformal predictions manually on a trained XGBoost model, you can follow these steps:\n",
      "\n",
      "1. Load the trained XGBoost model and the testing data:\n",
      "```python\n",
      "import xgboost as xgb\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "# load the trained XGBoost model\n",
      "model = xgb.XGBClassifier()\n",
      "model.load_model(\"./models/xgb_model.json\")\n",
      "\n",
      "# load the testing data\n",
      "test_data = pd.read_csv(\"./dataset/Sepsis_Processed_IC.csv\")\n",
      "```\n",
      "2. Preprocess the testing data:\n",
      "```python\n",
      "# labels and features separation\n",
      "X = test_data.drop(columns=['Target'], axis=1)\n",
      "y = test_data['Target']\n",
      "\n",
      "# one hot encoding the category columns\n",
      "category_columns = X.select_dtypes(include=['object']).columns\n",
      "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
      "X_encoded = one_hot_encoder.fit_transform(X[category_columns])\n",
      "X_encoded = pd.DataFrame(X_encoded, columns=one_hot_encoder.get_feature_names_out(category_columns))\n",
      "X = pd.concat([X, X_encoded], axis=1)\n",
      "X.drop(columns=category_columns, inplace=True)\n",
      "\n",
      "# convert bool to int\n",
      "bool_columns = X.select_dtypes(include=['bool']).columns\n",
      "for column in bool_columns:\n",
      "    X[column] = X[column].astype('int')\n",
      "\n",
      "# standardize the data using robust scaler\n",
      "scaler = RobustScaler()\n",
      "scaled_columns = ['age', 'max_activity_count', 'duration_since_reg', 'crp', 'lacticacid', 'hours_past_midnight', 'duration_last_event']\n",
      "X[scaled_columns] = scaler.fit_transform(X[scaled_columns])\n",
      "```\n",
      "3. Compute the conformal predictions:\n",
      "```python\n",
      "# compute the conformal predictions\n",
      "conformal_predictions = model.predict(X)\n",
      "confidence_scores = model.predict_proba(X)[:, 1]\n",
      "```\n",
      "4. Evaluate the conformal predictions:\n",
      "```python\n",
      "# evaluate the conformal predictions\n",
      "accuracy = accuracy_score(y, conformal_predictions)\n",
      "print(\"Accuracy:\", accuracy)\n",
      "```\n",
      "Note that this is just a basic example of how to compute conformal predictions manually on an XGBoost model using the provided code. You may need to adjust the preprocessing steps and the hyperparameters of the model based on your specific use case.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using Mistral API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: summary_tool_tabular_classification_binary\n",
      "Action Input: {'input': 'how to train xgboost model for sepsis dataset?'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: To train an XGBoost model for the Sepsis dataset, you would first need to preprocess your data. This includes loading the dataset, separating labels and features, handling missing values, one-hot encoding categorical columns, converting boolean columns to integers, and standardizing numerical columns.\n",
      "\n",
      "Once your data is preprocessed, you can split it into a training set and a test set using stratified sampling. Then, you can initialize the XGBoost model with specified parameters such as the number of estimators, learning rate, depth, and objective.\n",
      "\n",
      "After initializing the model, you can train it on the training set using the `fit` method. Once the model is trained, you can make predictions on the test set using the `predict` method and calculate the prediction probabilities using the `predict_proba` method.\n",
      "\n",
      "Finally, you can evaluate the model's performance by calculating metrics such as ROC AUC and average precision, and by plotting the ROC curve and precision-recall curve. If needed, you can also tune the model's threshold for optimal performance.\n",
      "\n",
      "Here is a simplified example of how you might do this:\n",
      "\n",
      "```python\n",
      "# model initialization\n",
      "clf = XGBClassifier(random_state=42, n_jobs=-1, eval_metric='logloss', scale_pos_weight=(len(class_0_train) / len(class_1_train)), use_label_encoder=False, verbosity=2, objective='binary:logistic', max_depth=6, learning_rate=0.01, n_estimators=500, subsample=0.8, colsample_bytree=0.6, reg_alpha=0.5, reg_lambda=1, oob_score=True)\n",
      "\n",
      "# training and prediction\n",
      "clf.fit(X_train_proper, y_train_proper) # train the model on the small training set\n",
      "prediction_prob_test = clf.predict_proba(X_test) # get the prediction probabilities for the test set\n",
      "predictions = clf.predict(X_test) # get the predictions for the test set\n",
      "\n",
      "# evaluation\n",
      "roc_auc = roc_auc_score(y_test, prediction_prob_test[:,1]) #\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: The current language of the user is: English. I have enough information to answer the question without using any more tools.\n",
      "Answer: To train an XGBoost model for the Sepsis dataset, you would first need to preprocess your data. This includes loading the dataset, separating labels and features, handling missing values, one-hot encoding categorical columns, converting boolean columns to integers, and standardizing numerical columns.\n",
      "\n",
      "Once your data is preprocessed, you can split it into a training set and a test set using stratified sampling. Then, you can initialize the XGBoost model with specified parameters such as the number of estimators, learning rate, depth, and objective.\n",
      "\n",
      "After initializing the model, you can train it on the training set using the `fit` method. Once the model is trained, you can make predictions on the test set using the `predict` method and calculate the prediction probabilities using the `predict_proba` method.\n",
      "\n",
      "Finally, you can evaluate the model's performance by calculating metrics such as ROC AUC and average precision, and by plotting the ROC curve and precision-recall curve. If needed, you can also tune the model's threshold for optimal performance.\n",
      "\n",
      "Here is a simplified example of how you might do this:\n",
      "\n",
      "```python\n",
      "# model initialization\n",
      "clf = XGBClassifier(random_state=42, n_jobs=-1, eval_metric='logloss', scale_pos_weight=(len(class_0_train) / len(class_1_train)), use_label_encoder=False, verbosity=2, objective='binary:logistic', max_depth=6, learning_rate=0.01, n_estimators=500, subsample=0.8, colsample_bytree=0.6, reg_alpha=0.5, reg_lambda=1, oob_score=True)\n",
      "\n",
      "# training and prediction\n",
      "clf.fit(X_train_proper, y_train_proper) # train the model on the small training set\n",
      "prediction_prob_test = clf.predict_proba(X_test) # get the prediction probabilities for the test set\n",
      "predictions = clf.predict(X_test) # get the predictions for the test\n",
      "\u001b[0mTo train an XGBoost model for the Sepsis dataset, you would first need to preprocess your data. This includes loading the dataset, separating labels and features, handling missing values, one-hot encoding categorical columns, converting boolean columns to integers, and standardizing numerical columns.\n",
      "\n",
      "Once your data is preprocessed, you can split it into a training set and a test set using stratified sampling. Then, you can initialize the XGBoost model with specified parameters such as the number of estimators, learning rate, depth, and objective.\n",
      "\n",
      "After initializing the model, you can train it on the training set using the `fit` method. Once the model is trained, you can make predictions on the test set using the `predict` method and calculate the prediction probabilities using the `predict_proba` method.\n",
      "\n",
      "Finally, you can evaluate the model's performance by calculating metrics such as ROC AUC and average precision, and by plotting the ROC curve and precision-recall curve. If needed, you can also tune the model's threshold for optimal performance.\n",
      "\n",
      "Here is a simplified example of how you might do this:\n",
      "\n",
      "```python\n",
      "# model initialization\n",
      "clf = XGBClassifier(random_state=42, n_jobs=-1, eval_metric='logloss', scale_pos_weight=(len(class_0_train) / len(class_1_train)), use_label_encoder=False, verbosity=2, objective='binary:logistic', max_depth=6, learning_rate=0.01, n_estimators=500, subsample=0.8, colsample_bytree=0.6, reg_alpha=0.5, reg_lambda=1, oob_score=True)\n",
      "\n",
      "# training and prediction\n",
      "clf.fit(X_train_proper, y_train_proper) # train the model on the small training set\n",
      "prediction_prob_test = clf.predict_proba(X_test) # get the prediction probabilities for the test set\n",
      "predictions = clf.predict(X_test) # get the predictions for the test\n"
     ]
    }
   ],
   "source": [
    "response = await agent.achat(\"how to train xgboost model for sepsis dataset?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActionReasoningStep -> thought='The current language of the user is: English. I need to use a tool to help me answer the question.' action='summary_tool_tabular_classification_binary' action_input={'input': 'how to train xgboost model for sepsis dataset?'}\n",
      "\n",
      "ObservationReasoningStep -> observation=\"To train an XGBoost model for the Sepsis dataset, you would first need to preprocess your data. This includes loading the dataset, separating labels and features, handling missing values, one-hot encoding categorical columns, converting boolean columns to integers, and standardizing numerical columns.\\n\\nOnce your data is preprocessed, you can split it into a training set and a test set using stratified sampling. Then, you can initialize the XGBoost model with specified parameters such as the number of estimators, learning rate, depth, and objective.\\n\\nAfter initializing the model, you can train it on the training set using the `fit` method. Once the model is trained, you can make predictions on the test set using the `predict` method and calculate the prediction probabilities using the `predict_proba` method.\\n\\nFinally, you can evaluate the model's performance by calculating metrics such as ROC AUC and average precision, and by plotting the ROC curve and precision-recall curve. If needed, you can also tune the model's threshold for optimal performance.\\n\\nHere is a simplified example of how you might do this:\\n\\n```python\\n# model initialization\\nclf = XGBClassifier(random_state=42, n_jobs=-1, eval_metric='logloss', scale_pos_weight=(len(class_0_train) / len(class_1_train)), use_label_encoder=False, verbosity=2, objective='binary:logistic', max_depth=6, learning_rate=0.01, n_estimators=500, subsample=0.8, colsample_bytree=0.6, reg_alpha=0.5, reg_lambda=1, oob_score=True)\\n\\n# training and prediction\\nclf.fit(X_train_proper, y_train_proper) # train the model on the small training set\\nprediction_prob_test = clf.predict_proba(X_test) # get the prediction probabilities for the test set\\npredictions = clf.predict(X_test) # get the predictions for the test set\\n\\n# evaluation\\nroc_auc = roc_auc_score(y_test, prediction_prob_test[:,1]) #\" return_direct=False\n",
      "\n",
      "ResponseReasoningStep -> thought='The current language of the user is: English. I have enough information to answer the question without using any more tools.' response=\"To train an XGBoost model for the Sepsis dataset, you would first need to preprocess your data. This includes loading the dataset, separating labels and features, handling missing values, one-hot encoding categorical columns, converting boolean columns to integers, and standardizing numerical columns.\\n\\nOnce your data is preprocessed, you can split it into a training set and a test set using stratified sampling. Then, you can initialize the XGBoost model with specified parameters such as the number of estimators, learning rate, depth, and objective.\\n\\nAfter initializing the model, you can train it on the training set using the `fit` method. Once the model is trained, you can make predictions on the test set using the `predict` method and calculate the prediction probabilities using the `predict_proba` method.\\n\\nFinally, you can evaluate the model's performance by calculating metrics such as ROC AUC and average precision, and by plotting the ROC curve and precision-recall curve. If needed, you can also tune the model's threshold for optimal performance.\\n\\nHere is a simplified example of how you might do this:\\n\\n```python\\n# model initialization\\nclf = XGBClassifier(random_state=42, n_jobs=-1, eval_metric='logloss', scale_pos_weight=(len(class_0_train) / len(class_1_train)), use_label_encoder=False, verbosity=2, objective='binary:logistic', max_depth=6, learning_rate=0.01, n_estimators=500, subsample=0.8, colsample_bytree=0.6, reg_alpha=0.5, reg_lambda=1, oob_score=True)\\n\\n# training and prediction\\nclf.fit(X_train_proper, y_train_proper) # train the model on the small training set\\nprediction_prob_test = clf.predict_proba(X_test) # get the prediction probabilities for the test set\\npredictions = clf.predict(X_test) # get the predictions for the test\" is_streaming=False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for resoning_step in agent.get_completed_tasks()[0].extra_state[\"current_reasoning\"]:\n",
    "    print(f\"{resoning_step.__class__.__name__} -> {resoning_step}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To train an XGBoost model for the Sepsis dataset, you would first need to preprocess your data. This includes loading the dataset, separating labels and features, handling missing values, one-hot encoding categorical columns, converting boolean columns to integers, and standardizing numerical columns.\n",
      "\n",
      "Once your data is preprocessed, you can split it into a training set and a test set using stratified sampling. Then, you can initialize the XGBoost model with specified parameters such as the number of estimators, learning rate, depth, and objective.\n",
      "\n",
      "After initializing the model, you can train it on the training set using the `fit` method. Once the model is trained, you can make predictions on the test set using the `predict` method and calculate the prediction probabilities using the `predict_proba` method.\n",
      "\n",
      "Finally, you can evaluate the model's performance by calculating metrics such as ROC AUC and average precision, and by plotting the ROC curve and precision-recall curve. If needed, you can also tune the model's threshold for optimal performance.\n",
      "\n",
      "Here is a simplified example of how you might do this:\n",
      "\n",
      "```python\n",
      "# model initialization\n",
      "clf = XGBClassifier(random_state=42, n_jobs=-1, eval_metric='logloss', scale_pos_weight=(len(class_0_train) / len(class_1_train)), use_label_encoder=False, verbosity=2, objective='binary:logistic', max_depth=6, learning_rate=0.01, n_estimators=500, subsample=0.8, colsample_bytree=0.6, reg_alpha=0.5, reg_lambda=1, oob_score=True)\n",
      "\n",
      "# training and prediction\n",
      "clf.fit(X_train_proper, y_train_proper) # train the model on the small training set\n",
      "prediction_prob_test = clf.predict_proba(X_test) # get the prediction probabilities for the test set\n",
      "predictions = clf.predict(X_test) # get the predictions for the test\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The current language of the user is English. I need to provide the code for computing conformal prediction manually on a trained model. However, I don't have the necessary tools to generate the code directly. I will explain the process in a way that the user can write the code themselves.\n",
      "Answer: To compute conformal prediction manually on a trained model, you can follow these steps:\n",
      "\n",
      "1. Fit your model on the training data.\n",
      "2. Compute non-conformity scores for the calibration set. Non-conformity scores measure how different a new example is from the examples used to train the model. In the case of classification, a common choice for non-conformity score is the difference between the maximum prediction probability and the probability assigned to the true class.\n",
      "3. Sort the non-conformity scores computed in step 2 and store them in an array.\n",
      "4. For a new test example, compute its non-conformity score using the same method as in step 2.\n",
      "5. To compute the p-value for the test example, calculate the fraction of calibration examples that have a non-conformity score greater than or equal to the test example's non-conformity score.\n",
      "6. To obtain a prediction set for the test example, include all classes whose p-values are greater than a significance level alpha.\n",
      "\n",
      "Here is a simplified example of how you might do this in Python:\n",
      "\n",
      "```python\n",
      "# assume you have a trained model `clf` and calibration data `X_calib`, `y_calib`\n",
      "\n",
      "# compute non-conformity scores for calibration data\n",
      "scores_calib = []\n",
      "for i in range(len(X_calib)):\n",
      "    pred_proba = clf.predict_proba(X_calib[i].reshape(1, -1))\n",
      "    scores_calib.append(1 - pred_proba[0][y_calib[i]])\n",
      "\n",
      "# sort the scores\n",
      "scores_calib.sort()\n",
      "\n",
      "# compute non-conformity score for test example\n",
      "test_example = X_test[0]\n",
      "pred_proba_test = clf.predict_proba(test_example.reshape(1, -1))\n",
      "score_test = 1 - pred_proba\n",
      "\u001b[0mTo compute conformal prediction manually on a trained model, you can follow these steps:\n",
      "\n",
      "1. Fit your model on the training data.\n",
      "2. Compute non-conformity scores for the calibration set. Non-conformity scores measure how different a new example is from the examples used to train the model. In the case of classification, a common choice for non-conformity score is the difference between the maximum prediction probability and the probability assigned to the true class.\n",
      "3. Sort the non-conformity scores computed in step 2 and store them in an array.\n",
      "4. For a new test example, compute its non-conformity score using the same method as in step 2.\n",
      "5. To compute the p-value for the test example, calculate the fraction of calibration examples that have a non-conformity score greater than or equal to the test example's non-conformity score.\n",
      "6. To obtain a prediction set for the test example, include all classes whose p-values are greater than a significance level alpha.\n",
      "\n",
      "Here is a simplified example of how you might do this in Python:\n",
      "\n",
      "```python\n",
      "# assume you have a trained model `clf` and calibration data `X_calib`, `y_calib`\n",
      "\n",
      "# compute non-conformity scores for calibration data\n",
      "scores_calib = []\n",
      "for i in range(len(X_calib)):\n",
      "    pred_proba = clf.predict_proba(X_calib[i].reshape(1, -1))\n",
      "    scores_calib.append(1 - pred_proba[0][y_calib[i]])\n",
      "\n",
      "# sort the scores\n",
      "scores_calib.sort()\n",
      "\n",
      "# compute non-conformity score for test example\n",
      "test_example = X_test[0]\n",
      "pred_proba_test = clf.predict_proba(test_example.reshape(1, -1))\n",
      "score_test = 1 - pred_proba\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"give me the code for computing conformal prediction manually on the trained model\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To compute conformal prediction manually on a trained model, you can follow these steps:\n",
      "\n",
      "1. Fit your model on the training data.\n",
      "2. Compute non-conformity scores for the calibration set. Non-conformity scores measure how different a new example is from the examples used to train the model. In the case of classification, a common choice for non-conformity score is the difference between the maximum prediction probability and the probability assigned to the true class.\n",
      "3. Sort the non-conformity scores computed in step 2 and store them in an array.\n",
      "4. For a new test example, compute its non-conformity score using the same method as in step 2.\n",
      "5. To compute the p-value for the test example, calculate the fraction of calibration examples that have a non-conformity score greater than or equal to the test example's non-conformity score.\n",
      "6. To obtain a prediction set for the test example, include all classes whose p-values are greater than a significance level alpha.\n",
      "\n",
      "Here is a simplified example of how you might do this in Python:\n",
      "\n",
      "```python\n",
      "# assume you have a trained model `clf` and calibration data `X_calib`, `y_calib`\n",
      "\n",
      "# compute non-conformity scores for calibration data\n",
      "scores_calib = []\n",
      "for i in range(len(X_calib)):\n",
      "    pred_proba = clf.predict_proba(X_calib[i].reshape(1, -1))\n",
      "    scores_calib.append(1 - pred_proba[0][y_calib[i]])\n",
      "\n",
      "# sort the scores\n",
      "scores_calib.sort()\n",
      "\n",
      "# compute non-conformity score for test example\n",
      "test_example = X_test[0]\n",
      "pred_proba_test = clf.predict_proba(test_example.reshape(1, -1))\n",
      "score_test = 1 - pred_proba\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_pipeline import QueryPipeline\n",
    "from llama_index.core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(995, 59)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>Target</th>\n",
       "      <th>age</th>\n",
       "      <th>max_activity_count</th>\n",
       "      <th>duration_since_reg</th>\n",
       "      <th>crp</th>\n",
       "      <th>lacticacid</th>\n",
       "      <th>leucocytes</th>\n",
       "      <th>diagnose</th>\n",
       "      <th>diagnosticartastrup</th>\n",
       "      <th>...</th>\n",
       "      <th>IV Liquid =&gt; ER Triage</th>\n",
       "      <th>IV Liquid =&gt; IV Antibiotics</th>\n",
       "      <th>LacticAcid =&gt; CRP</th>\n",
       "      <th>LacticAcid =&gt; ER Triage</th>\n",
       "      <th>LacticAcid =&gt; IV Liquid</th>\n",
       "      <th>LacticAcid =&gt; Leucocytes</th>\n",
       "      <th>Leucocytes =&gt; CRP</th>\n",
       "      <th>Leucocytes =&gt; ER Triage</th>\n",
       "      <th>Leucocytes =&gt; IV Liquid</th>\n",
       "      <th>Leucocytes =&gt; LacticAcid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>5</td>\n",
       "      <td>31.166667</td>\n",
       "      <td>210</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAA</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>2.466667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AB</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>1.516667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABA</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>20.616667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UC</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  case_id  Target  age  max_activity_count  duration_since_reg  crp  \\\n",
       "0       A       0   85                   5           31.166667  210   \n",
       "1      AA       0   75                   2            0.683333    0   \n",
       "2     AAA       0   60                   2            2.466667    0   \n",
       "3      AB       0   90                   2            1.516667    0   \n",
       "4     ABA       0   75                   2           20.616667    0   \n",
       "\n",
       "   lacticacid  leucocytes diagnose  diagnosticartastrup  ...  \\\n",
       "0         2.2         9.6        A                 True  ...   \n",
       "1         0.0         0.0  missing                False  ...   \n",
       "2         0.0         0.0        C                False  ...   \n",
       "3         0.0         0.0  missing                 True  ...   \n",
       "4         0.0         0.0       UC                False  ...   \n",
       "\n",
       "   IV Liquid => ER Triage  IV Liquid => IV Antibiotics  LacticAcid => CRP  \\\n",
       "0                       0                            0                  0   \n",
       "1                       0                            0                  0   \n",
       "2                       0                            0                  0   \n",
       "3                       0                            0                  0   \n",
       "4                       0                            0                  0   \n",
       "\n",
       "   LacticAcid => ER Triage  LacticAcid => IV Liquid  LacticAcid => Leucocytes  \\\n",
       "0                        1                        0                         0   \n",
       "1                        0                        0                         0   \n",
       "2                        0                        0                         0   \n",
       "3                        0                        0                         0   \n",
       "4                        0                        0                         0   \n",
       "\n",
       "   Leucocytes => CRP  Leucocytes => ER Triage  Leucocytes => IV Liquid  \\\n",
       "0                  1                        0                        0   \n",
       "1                  0                        0                        0   \n",
       "2                  0                        0                        0   \n",
       "3                  0                        0                        0   \n",
       "4                  0                        0                        0   \n",
       "\n",
       "   Leucocytes => LacticAcid  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data_csv/Sepsis_Processed_IC.csv\")\n",
    "df['diagnose'] = df['diagnose'].fillna(\"missing\")\n",
    "\n",
    "# df = pd.read_csv(\"./data_wiki/WikiTableQuestions/csv/200-csv/42.csv\")\n",
    "print(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(298, 59)\n"
     ]
    }
   ],
   "source": [
    "# keep only 0.20 of the data\n",
    "df = df.sample(frac=0.30, random_state=42)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = \"\"\"\\\n",
    "Here's a serialized table.\n",
    "\n",
    "{serialized_table}\n",
    "\n",
    "Given this table please answer the question: {question}\n",
    "Answer: \"\"\"\n",
    "prompt = PromptTemplate(prompt_str)\n",
    "prompt_c = prompt.as_query_component(partial={\"serialized_table\": serialize_table(df)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: To answer your question, I'll first explain that in this table, the \"Target\" column seems to be the one indicating whether a case is positive or not. The values in this column are either 0 or 1. Typically, 1 represents a positive case and 0 represents a negative case.\n",
      "\n",
      "Upon examining the table, there are only three instances where the \"Target\" column has a value of 1. These are in rows 23, 28, and 42.\n",
      "\n",
      "Therefore, there are 3 positive cases in this table.\n"
     ]
    }
   ],
   "source": [
    "p = QueryPipeline(chain=[prompt_c, llm])\n",
    "# response = p.run(\"Which televised ABC game had the greatest attendance?\")\n",
    "# response = p.run(\"Who won best Director in the 1972 Academy Awards?\")\n",
    "# response = p.run(\"What was the precipitation in inches during June?\")\n",
    "response = p.run(\"how many positive cases?\")\n",
    "# response = p.run(\"What is the average age of the patients?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = ChainOfTableQueryEngine(df, llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;32m> Iteration: 0\n",
      "\u001b[0m\u001b[1;3;34m> Current table:\n",
      "col : case_id | Target | age | max_activity_count | duration_since_reg | crp | lacticacid | leucocytes | diagnose | diagnosticartastrup | diagnosticblood | diagnosticecg | diagnosticic | diagnosticlacticacid | diagnosticliquor | diagnosticother | diagnosticsputum | diagnosticurinaryculture | diagnosticurinarysediment | diagnosticxthorax | resource | disfuncorg | hypotensie | hypoxie | infectionsuspected | infusion | oligurie | sirscritheartrate | sirscritleucos | sirscrittachypnea | sirscrittemperature | sirscriteria2ormore | hours_past_midnight | duration_last_event | CRP => ER Triage | CRP => IV Liquid | CRP => LacticAcid | CRP => Leucocytes | ER Registration => CRP | ER Registration => ER Sepsis Triage | ER Registration => ER Triage | ER Registration => IV Liquid | ER Registration => LacticAcid | ER Registration => Leucocytes | ER Sepsis Triage => ER Triage | ER Sepsis Triage => IV Antibiotics | ER Sepsis Triage => IV Liquid | IV Antibiotics => ER Triage | IV Liquid => ER Sepsis Triage | IV Liquid => ER Triage | IV Liquid => IV Antibiotics | LacticAcid => CRP | LacticAcid => ER Triage | LacticAcid => IV Liquid | LacticAcid => Leucocytes | Leucocytes => CRP | Leucocytes => ER Triage | Leucocytes => IV Liquid | Leucocytes => LacticAcid\n",
      "row 1 : YB | 0 | 85 | 2 | 12.95 | 0 | 0.0 | 0.0 | B | True | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | False | True | True | 20.36055555555556 | 0.7333333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 2 : NLA | 0 | 30 | 2 | 14.666666666666666 | 0 | 0.0 | 0.0 | missing | False | False | False | True | False | False | False | False | False | False | True | A | False | False | False | True | False | False | True | False | False | True | True | 20.564722222222223 | 0.5 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 3 : ON | 0 | 85 | 2 | 7.449999999999999 | 0 | 0.0 | 0.0 | SB | True | True | True | True | True | False | False | False | False | False | True | A | False | False | False | True | True | False | True | False | True | True | True | 15.142777777777775 | 22.98333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 4 : R | 0 | 45 | 2 | 1.8833333333333333 | 0 | 0.0 | 0.0 | missing | False | False | False | False | False | False | False | False | False | False | False | A | False | False | False | False | False | False | False | False | False | False | False | 12.637777777777778 | 0.3333333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 5 : QGA | 0 | 60 | 2 | 5.316666666666666 | 0 | 0.0 | 0.0 | missing | False | True | True | True | True | False | True | False | True | True | True | L | False | False | False | True | False | False | True | False | True | True | True | 13.574722222222222 | 0.85 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 6 : L | 0 | 85 | 2 | 3.35 | 0 | 0.0 | 0.0 | J | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 18.7875 | 2.066666666666667 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 7 : WFA | 0 | 65 | 2 | 36.85 | 0 | 0.0 | 0.0 | Y | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 23.30472222222222 | 0.25 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 8 : SJ | 0 | 60 | 2 | 2.1833333333333336 | 0 | 0.0 | 0.0 | DB | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 12.13111111111111 | 26.95 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 9 : EI | 0 | 90 | 2 | 1.3166666666666669 | 0 | 0.0 | 0.0 | YA | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 14.1675 | 1.0333333333333334 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 10 : PLA | 0 | 80 | 2 | 1.8333333333333333 | 0 | 0.0 | 0.0 | D | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | False | True | 18.74333333333333 | 0.6833333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 11 : WMA | 0 | 20 | 2 | 48.45 | 0 | 0.0 | 0.0 | missing | False | False | False | False | False | False | False | False | False | False | False | A | False | False | False | False | False | False | True | False | False | True | True | 15.490555555555556 | 0.7833333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 12 : LK | 0 | 75 | 2 | 4.333333333333333 | 0 | 0.0 | 0.0 | C | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | False | True | 21.665277777777774 | 1.0166666666666666 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 13 : VZ | 0 | 25 | 2 | 7.916666666666668 | 0 | 0.0 | 0.0 | missing | False | False | False | False | False | False | False | False | False | False | False | A | False | False | False | False | False | False | False | False | False | False | False | 15.891666666666667 | 30.53333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 14 : P | 0 | 20 | 2 | 25.21666666666667 | 0 | 0.0 | 0.0 | missing | False | False | False | False | False | False | False | False | False | False | False | A | False | False | False | False | False | False | False | False | False | False | False | 9.66 | 56.45 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 15 : BY | 0 | 30 | 2 | 15.283333333333331 | 0 | 0.0 | 0.0 | missing | False | True | False | True | False | False | True | False | False | True | False | A | False | False | False | True | False | False | True | False | False | True | True | 12.510833333333334 | 0.3833333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 16 : JJ | 0 | 85 | 2 | 31.116666666666667 | 0 | 0.0 | 0.0 | N | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | False | False | True | True | True | 14.629722222222222 | 0.3333333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 17 : SN | 0 | 75 | 2 | 14.066666666666666 | 0 | 0.0 | 0.0 | missing | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 15.163333333333334 | 0.4 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 18 : DIA | 0 | 45 | 2 | 2.716666666666667 | 0 | 0.0 | 0.0 | missing | False | False | False | False | False | False | False | False | False | False | False | A | False | False | False | False | False | False | False | False | False | False | False | 21.006944444444443 | 0.3833333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 19 : EA | 0 | 70 | 2 | 14.233333333333334 | 0 | 0.0 | 0.0 | D | False | True | True | True | False | False | False | False | False | False | True | A | False | False | False | True | True | False | True | False | False | True | True | 12.476944444444444 | 2.3833333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 20 : HGA | 0 | 75 | 2 | 3.633333333333333 | 0 | 0.0 | 0.0 | C | True | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | False | True | True | 6.978611111111111 | 17.65 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 21 : WG | 0 | 55 | 2 | 2.683333333333333 | 0 | 0.0 | 0.0 | U | False | True | True | True | True | False | False | False | False | False | True | A | False | False | False | True | True | False | True | False | True | True | True | 6.205 | 2.433333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 22 : ID | 0 | 70 | 2 | 37.78333333333333 | 0 | 0.0 | 0.0 | missing | False | False | False | False | False | False | False | False | False | False | False | A | False | False | False | False | False | False | False | False | False | False | False | 12.348611111111111 | 0.3333333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 23 : TN | 1 | 75 | 2 | 5.966666666666667 | 0 | 0.0 | 0.0 | B | True | True | True | True | True | False | False | False | False | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 22.413611111111116 | 0.6666666666666666 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 24 : BS | 0 | 90 | 2 | 10.51666666666667 | 0 | 0.0 | 0.0 | KC | False | True | True | True | True | False | False | False | True | True | True | L | False | False | False | True | True | False | True | False | False | True | True | 14.294722222222225 | 16.716666666666665 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 25 : JAA | 0 | 65 | 2 | 9.650000000000002 | 0 | 0.0 | 0.0 | ND | False | False | True | True | False | False | False | False | False | False | True | A | False | False | False | True | False | False | True | False | True | True | True | 6.585833333333333 | 3.0166666666666666 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 26 : JCA | 0 | 90 | 2 | 11.9 | 0 | 0.0 | 0.0 | JC | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | False | True | True | 13.405833333333334 | 0.5333333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 27 : CP | 0 | 90 | 2 | 4.05 | 0 | 0.0 | 0.0 | Q | True | True | True | True | True | False | False | False | False | False | True | A | False | False | False | True | True | False | True | True | True | True | True | 13.362777777777778 | 0.2 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 28 : GNA | 1 | 55 | 2 | 29.96666666666666 | 0 | 0.0 | 0.0 | G | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 0.4247222222222222 | 3.216666666666667 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 29 : VIA | 1 | 65 | 2 | 0.8 | 0 | 0.0 | 0.0 | G | True | True | True | True | True | False | False | False | False | False | True | A | False | False | False | True | True | True | False | False | True | True | True | 1.6033333333333333 | 0.4333333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 30 : DK | 0 | 80 | 5 | 10.5 | 0 | 1.9 | 14.4 | E | True | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 6.550833333333333 | 0.35 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 0 | 0 | 0\n",
      "row 31 : EN | 0 | 85 | 2 | 12.65 | 0 | 0.0 | 0.0 | missing | True | True | True | True | True | False | False | True | True | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 9.93388888888889 | 0.4666666666666667 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 32 : SV | 0 | 75 | 2 | 1.2333333333333334 | 0 | 0.0 | 0.0 | C | True | True | True | True | True | True | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 9.42027777777778 | 0.15 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 33 : RT | 0 | 60 | 2 | 21.883333333333333 | 0 | 0.0 | 0.0 | K | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | False | True | True | 20.60638888888889 | 8.05 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 34 : YO | 0 | 80 | 2 | 1.6666666666666663 | 0 | 0.0 | 0.0 | XB | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | False | True | 11.915277777777778 | 3.1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 35 : HP | 0 | 65 | 2 | 2.0166666666666666 | 0 | 0.0 | 0.0 | C | False | False | False | False | False | False | False | False | False | False | False | A | False | False | False | False | False | False | True | False | False | True | False | 6.5777777777777775 | 0.4666666666666667 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 36 : VAA | 1 | 85 | 2 | 10.25 | 0 | 0.0 | 0.0 | B | True | True | True | True | True | False | False | False | True | True | True | L | False | True | False | True | True | False | True | False | True | True | True | 14.151388888888889 | 0.3 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 37 : HQ | 0 | 65 | 2 | 0.9333333333333332 | 0 | 0.0 | 0.0 | E | True | True | False | True | True | False | False | False | False | False | False | A | False | False | False | True | True | False | True | False | True | True | True | 15.412222222222224 | 3.65 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 38 : QS | 0 | 55 | 2 | 22.566666666666663 | 0 | 0.0 | 0.0 | E | False | True | True | True | True | False | False | False | True | False | True | L | False | False | False | True | True | False | True | False | False | True | True | 16.711388888888887 | 9.933333333333334 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 39 : ZI | 0 | 85 | 2 | 3.4499999999999997 | 0 | 0.0 | 0.0 | HA | False | True | True | True | True | False | False | False | False | False | True | A | False | False | False | True | True | False | True | False | True | True | True | 22.415 | 16.5 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 40 : IE | 0 | 55 | 2 | 5.65 | 0 | 0.0 | 0.0 | HA | False | False | False | False | False | False | False | False | False | False | False | A | False | False | False | False | False | False | False | False | False | False | False | 18.046666666666667 | 0.7 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 41 : BKA | 0 | 35 | 2 | 7.783333333333334 | 0 | 0.0 | 0.0 | BB | True | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 16.719444444444445 | 0.2666666666666666 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 42 : HKA | 0 | 85 | 2 | 8.666666666666666 | 0 | 0.0 | 0.0 | C | False | True | True | True | True | False | False | False | False | True | True | A | False | False | False | True | True | False | True | False | False | True | True | 15.153333333333334 | 0.2166666666666666 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 43 : QE | 1 | 60 | 2 | 7.816666666666666 | 0 | 0.0 | 0.0 | G | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | False | True | True | 12.11111111111111 | 3.6666666666666665 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 44 : PZ | 0 | 90 | 2 | 4.283333333333333 | 0 | 0.0 | 0.0 | H | True | True | True | True | True | False | False | False | False | False | True | A | False | False | False | True | True | False | True | False | True | False | True | 11.769166666666669 | 7.566666666666666 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 45 : JI | 0 | 80 | 2 | 1.9666666666666668 | 0 | 0.0 | 0.0 | missing | True | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 16.629444444444445 | 0.4 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 46 : ALA | 0 | 75 | 2 | 2.55 | 0 | 0.0 | 0.0 | AA | False | True | True | True | True | False | False | True | False | True | True | A | False | False | False | True | True | False | True | False | False | True | True | 17.529166666666665 | 0.3166666666666666 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 47 : AQ | 0 | 85 | 2 | 1.9666666666666668 | 0 | 0.0 | 0.0 | C | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | False | True | True | 19.72833333333333 | 0.2666666666666666 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 48 : TM | 0 | 75 | 2 | 14.4 | 0 | 0.0 | 0.0 | missing | True | True | True | True | True | False | False | False | False | False | True | A | False | False | False | True | True | False | True | False | True | True | True | 23.477777777777774 | 0.95 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 49 : AEA | 0 | 85 | 2 | 7.666666666666667 | 0 | 0.0 | 0.0 | missing | True | True | True | True | True | False | False | True | False | False | True | A | False | False | False | True | True | False | True | False | True | True | True | 10.250833333333333 | 0.2666666666666666 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 50 : NG | 0 | 25 | 2 | 7.35 | 0 | 0.0 | 0.0 | missing | False | False | False | False | False | False | False | False | False | False | False | A | False | False | False | False | False | False | False | False | False | False | False | 10.435555555555556 | 0.2166666666666666 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 51 : TBA | 0 | 60 | 2 | 2.533333333333333 | 0 | 0.0 | 0.0 | C | True | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | False | True | True | 4.519722222222223 | 0.4 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 52 : PIA | 1 | 75 | 2 | 4.683333333333334 | 0 | 0.0 | 0.0 | GE | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | False | False | True | True | True | 21.569166666666668 | 0.6 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 53 : VA | 0 | 90 | 2 | 5.583333333333333 | 0 | 0.0 | 0.0 | C | True | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 19.008055555555558 | 0.25 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 54 : OEA | 0 | 90 | 2 | 3.85 | 0 | 0.0 | 0.0 | JC | False | True | True | True | False | False | False | False | False | False | True | A | False | False | False | True | True | False | True | False | False | True | True | 17.089444444444446 | 12.783333333333331 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 55 : QA | 0 | 90 | 2 | 15.833333333333332 | 0 | 0.0 | 0.0 | Q | True | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 19.89638888888889 | 0.3 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 56 : IK | 0 | 65 | 2 | 19.98333333333333 | 0 | 0.0 | 0.0 | missing | True | True | True | True | True | False | False | False | False | False | True | L | False | False | False | True | False | False | True | False | True | False | True | 11.175277777777778 | 0.65 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 57 : FY | 0 | 60 | 2 | 26.23333333333333 | 0 | 0.0 | 0.0 | D | False | True | True | True | True | False | False | False | False | False | True | A | False | False | False | True | True | False | True | False | False | True | True | 14.904166666666669 | 16.516666666666666 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 58 : PF | 0 | 85 | 2 | 3.3833333333333337 | 0 | 0.0 | 0.0 | C | True | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 14.706388888888888 | 1.8333333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 59 : F | 0 | 50 | 2 | 0.8666666666666667 | 0 | 0.0 | 0.0 | E | False | True | True | True | True | False | False | False | False | False | True | A | False | False | False | True | True | False | True | False | False | True | True | 18.949166666666667 | 0.3166666666666666 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 60 : LA | 0 | 85 | 2 | 11.933333333333334 | 0 | 0.0 | 0.0 | missing | False | False | False | False | False | False | False | False | False | False | False | A | False | False | False | False | False | False | False | False | False | False | False | 12.190833333333334 | 0.7333333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 61 : JEA | 0 | 70 | 2 | 8.516666666666667 | 0 | 0.0 | 0.0 | C | False | True | True | True | True | False | False | False | False | True | True | A | False | False | False | True | True | False | True | False | False | True | True | 20.65305555555556 | 0.4 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 62 : NR | 0 | 90 | 2 | 6.883333333333334 | 0 | 0.0 | 0.0 | HC | True | True | True | True | True | False | False | False | True | False | True | A | False | False | False | True | True | False | True | False | True | True | True | 10.265833333333331 | 0.3 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 63 : KGA | 0 | 80 | 2 | 4.733333333333333 | 0 | 0.0 | 0.0 | missing | False | False | False | False | False | False | False | False | False | False | False | A | False | False | False | False | False | False | False | False | False | False | False | 8.829722222222221 | 1.3 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 64 : CIA | 0 | 55 | 2 | 58.833333333333336 | 0 | 0.0 | 0.0 | missing | False | True | False | True | False | False | False | False | False | False | False | A | False | False | False | True | False | False | True | False | False | True | True | 20.385555555555555 | 0.2833333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 65 : PB | 0 | 80 | 2 | 1.7666666666666666 | 0 | 0.0 | 0.0 | V | False | True | True | True | True | False | False | False | False | False | True | A | False | False | False | True | True | False | True | False | True | True | True | 19.861666666666668 | 1.5 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 66 : SQ | 1 | 90 | 2 | 1.5 | 0 | 0.0 | 0.0 | G | False | False | False | False | False | False | False | False | False | False | False | A | False | False | False | False | False | False | False | False | False | False | False | 8.752777777777778 | 0.6 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 67 : VL | 0 | 70 | 2 | 6.3 | 0 | 0.0 | 0.0 | D | False | True | True | True | True | False | False | False | False | False | True | A | False | False | False | True | True | False | True | False | True | True | True | 5.165 | 0.2 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 68 : FW | 0 | 40 | 2 | 6.033333333333331 | 0 | 0.0 | 0.0 | B | True | True | True | True | True | False | False | True | True | True | True | A | False | False | False | True | True | False | True | True | True | True | True | 11.278333333333334 | 18.266666666666666 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 69 : HW | 0 | 75 | 2 | 2.15 | 0 | 0.0 | 0.0 | missing | False | False | False | False | False | False | False | False | False | False | False | L | False | False | False | False | False | False | False | False | False | False | False | 14.968333333333334 | 0.7166666666666667 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 70 : RHA | 0 | 40 | 2 | 22.33333333333333 | 0 | 0.0 | 0.0 | EE | False | False | False | False | False | False | False | False | False | False | False | A | False | False | False | False | False | False | False | False | False | False | False | 16.244722222222222 | 0.5333333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 71 : YK | 0 | 85 | 2 | 5.183333333333334 | 0 | 0.0 | 0.0 | HB | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 20.00555555555556 | 1.0333333333333334 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 72 : AZ | 0 | 50 | 2 | 20.633333333333333 | 0 | 0.0 | 0.0 | ID | True | True | True | True | True | False | False | False | True | False | True | A | False | False | False | True | True | False | True | False | False | True | True | 3.355833333333333 | 17.616666666666667 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 73 : FH | 0 | 70 | 2 | 2.5666666666666678 | 0 | 0.0 | 0.0 | K | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | False | False | False | False | True | True | True | 10.802777777777775 | 0.55 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 74 : MI | 0 | 85 | 2 | 5.65 | 0 | 0.0 | 0.0 | missing | False | True | False | True | True | False | False | False | True | True | True | A | False | False | False | True | False | False | True | False | True | True | True | 8.190277777777778 | 0.3166666666666666 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 75 : YI | 0 | 75 | 2 | 0.766666666666667 | 0 | 0.0 | 0.0 | C | True | True | True | True | True | False | False | False | True | True | True | A | True | True | False | True | True | False | True | False | True | True | True | 18.68 | 3.3666666666666667 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 76 : BO | 0 | 65 | 2 | 8.233333333333333 | 0 | 0.0 | 0.0 | missing | False | False | False | False | False | False | False | False | False | False | False | A | False | False | False | False | False | False | True | False | False | True | False | 16.764444444444443 | 0.3166666666666666 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 77 : YDA | 0 | 70 | 2 | 8.916666666666666 | 0 | 0.0 | 0.0 | UC | True | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 19.72222222222222 | 0.3 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 78 : BP | 1 | 85 | 2 | 4.3 | 0 | 0.0 | 0.0 | YB | False | False | False | False | False | False | False | False | False | False | False | L | False | False | False | False | False | False | False | False | False | False | False | 9.841944444444444 | 0.6833333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 79 : XBA | 1 | 55 | 2 | 9.4 | 0 | 0.0 | 0.0 | SD | False | True | True | True | True | False | False | False | False | False | True | A | False | False | False | True | True | False | True | False | False | True | True | 21.46555555555556 | 0.2833333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 80 : MJA | 0 | 70 | 2 | 23.83333333333333 | 0 | 0.0 | 0.0 | missing | False | True | False | True | True | False | False | False | False | False | False | A | False | False | False | False | True | False | True | False | False | True | False | 20.92888888888889 | 1.1333333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 81 : EF | 0 | 45 | 5 | 25.55 | 60 | 1.4 | 14.5 | K | False | True | True | True | False | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | False | True | True | 18.604166666666668 | 0.3833333333333333 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | 0\n",
      "row 82 : IB | 0 | 80 | 5 | 45.28333333333333 | 2590 | 1.3 | 6.8 | U | False | True | True | True | True | False | False | False | False | False | True | A | False | False | False | True | True | False | True | False | True | True | True | 0.2436111111111111 | 1.3166666666666669 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | 0 | 0\n",
      "row 83 : RS | 0 | 70 | 2 | 9.583333333333334 | 0 | 0.0 | 0.0 | H | False | True | True | True | True | False | False | False | False | False | True | A | False | False | False | True | True | False | True | False | True | False | True | 16.579166666666666 | 10.583333333333334 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 84 : JE | 0 | 90 | 2 | 13.25 | 0 | 0.0 | 0.0 | C | True | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | True | False | True | True | 17.564444444444444 | 0.1833333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 85 : PA | 0 | 70 | 2 | 5.366666666666665 | 0 | 0.0 | 0.0 | missing | False | True | True | True | True | False | False | False | False | False | True | A | False | False | False | False | False | False | False | False | False | False | False | 12.026388888888889 | 11.9 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 86 : FI | 0 | 90 | 2 | 2.6666666666666665 | 0 | 0.0 | 0.0 | missing | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 10.636666666666668 | 0.2833333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 87 : UX | 0 | 75 | 2 | 3.416666666666667 | 0 | 0.0 | 0.0 | missing | False | True | True | True | True | False | False | False | True | False | True | A | False | False | False | True | True | False | False | False | True | True | True | 13.689166666666669 | 0.3166666666666666 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 88 : HIA | 0 | 70 | 2 | 24.73333333333333 | 0 | 0.0 | 0.0 | HD | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | False | True | True | 17.570555555555554 | 0.4 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 89 : CEA | 0 | 90 | 2 | 5.583333333333332 | 0 | 0.0 | 0.0 | R | True | True | True | True | True | False | False | False | False | False | True | A | False | False | False | True | True | False | False | False | True | True | True | 10.444444444444445 | 20.75 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 90 : BMA | 0 | 55 | 2 | 9.316666666666666 | 0 | 0.0 | 0.0 | VB | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 16.404166666666665 | 0.2666666666666666 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 91 : XMA | 0 | 40 | 2 | 13.183333333333334 | 0 | 0.0 | 0.0 | missing | False | False | False | False | False | False | False | False | False | False | False | A | False | False | False | False | False | False | False | False | False | False | False | 0.2258333333333333 | 0.2 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 92 : SI | 0 | 60 | 2 | 9.916666666666666 | 0 | 0.0 | 0.0 | B | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 23.684444444444445 | 0.5666666666666667 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 93 : PI | 0 | 70 | 2 | 12.85 | 0 | 0.0 | 0.0 | K | True | True | True | True | True | False | False | False | False | False | True | A | False | False | False | True | True | False | True | False | True | True | True | 22.745555555555555 | 0.3833333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 94 : XHA | 1 | 70 | 2 | 0.9833333333333334 | 0 | 0.0 | 0.0 | G | True | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 22.416944444444443 | 4.0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 95 : FFA | 0 | 25 | 2 | 5.283333333333333 | 0 | 0.0 | 0.0 | missing | False | False | False | False | False | False | False | False | False | False | False | A | False | False | False | False | False | False | False | False | False | False | False | 0.2469444444444444 | 1.1833333333333331 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 96 : QV | 0 | 80 | 2 | 10.85 | 0 | 0.0 | 0.0 | E | False | True | True | True | True | False | False | False | True | True | True | A | True | False | False | True | True | False | True | False | False | True | True | 20.029166666666665 | 0.1666666666666666 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 97 : VDA | 0 | 55 | 2 | 7.366666666666666 | 0 | 0.0 | 0.0 | K | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 18.1775 | 0.2166666666666666 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 98 : YZ | 0 | 65 | 3 | 22.3 | 0 | 0.0 | 0.0 | D | False | True | True | True | True | False | False | False | False | False | True | A | False | False | False | True | True | False | True | False | True | True | True | 8.139722222222222 | 5.316666666666666 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 99 : FF | 0 | 40 | 2 | 9.7 | 0 | 0.0 | 0.0 | missing | False | True | True | True | True | False | False | False | True | True | True | A | False | False | False | True | True | False | True | False | True | True | True | 11.841944444444444 | 0.3 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "row 100 : WV | 0 | 75 | 2 | 5.4 | 0 | 0.0 | 0.0 | B | False | True | True | True | True | False | False | False | False | False | True | A | False | False | False | True | True | False | True | False | True | True | True | 12.142777777777775 | 0.2833333333333333 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# response = query_engine.query(\"Who won best Director in the 1972 Academy Awards?\")\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# response = query_engine.query(\"What was the precipitation in inches during June?\")\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# response = query_engine.query(\"Which televised ABC game had the greatest attendance?\")\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mquery_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhow many positive cases?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\conda_envs\\rag\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[0;32m    228\u001b[0m )\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32md:\\conda_envs\\rag\\lib\\site-packages\\llama_index\\core\\query_engine\\custom.py:45\u001b[0m, in \u001b[0;36mCustomQueryEngine.query\u001b[1;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     query_str \u001b[38;5;241m=\u001b[39m str_or_query_bundle\n\u001b[1;32m---> 45\u001b[0m raw_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcustom_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m     47\u001b[0m     Response(raw_response)\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(raw_response, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m raw_response\n\u001b[0;32m     50\u001b[0m )\n",
      "File \u001b[1;32md:\\conda_envs\\rag\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[0;32m    228\u001b[0m )\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32md:\\conda_envs\\rag\\lib\\site-packages\\llama_index\\packs\\tables\\chain_of_table\\base.py:689\u001b[0m, in \u001b[0;36mChainOfTableQueryEngine.custom_query\u001b[1;34m(self, query_str)\u001b[0m\n\u001b[0;32m    685\u001b[0m generate_args_chain \u001b[38;5;241m=\u001b[39m QP(\n\u001b[0;32m    686\u001b[0m     chain\u001b[38;5;241m=\u001b[39m[fn_prompt, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm], callback_manager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\n\u001b[0;32m    687\u001b[0m )\n\u001b[0;32m    688\u001b[0m raw_args \u001b[38;5;241m=\u001b[39m generate_args_chain\u001b[38;5;241m.\u001b[39mrun(question\u001b[38;5;241m=\u001b[39mquery_str)\n\u001b[1;32m--> 689\u001b[0m args, cur_table \u001b[38;5;241m=\u001b[39m \u001b[43mschema_mappings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_args_and_call_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcur_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_args\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    693\u001b[0m op_chain\u001b[38;5;241m.\u001b[39mappend((key, args))\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n",
      "File \u001b[1;32md:\\conda_envs\\rag\\lib\\site-packages\\llama_index\\packs\\tables\\chain_of_table\\base.py:274\u001b[0m, in \u001b[0;36mAddColumnSchema.parse_args_and_call_fn\u001b[1;34m(self, table, args)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_args_and_call_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m, table: pd\u001b[38;5;241m.\u001b[39mDataFrame, args: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m    273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse args and call function.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(table, args)\n",
      "File \u001b[1;32md:\\conda_envs\\rag\\lib\\site-packages\\llama_index\\packs\\tables\\chain_of_table\\base.py:261\u001b[0m, in \u001b[0;36mAddColumnSchema.parse_args\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Parse args.\"\"\"\u001b[39;00m\n\u001b[0;32m    260\u001b[0m regex_fn \u001b[38;5;241m=\u001b[39m _get_regex_parser_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregex)\n\u001b[1;32m--> 261\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[43mregex_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m value_args_regex \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue:(.*)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    264\u001b[0m value_regex_fn \u001b[38;5;241m=\u001b[39m _get_regex_parser_fn(value_args_regex)\n",
      "File \u001b[1;32md:\\conda_envs\\rag\\lib\\site-packages\\llama_index\\packs\\tables\\chain_of_table\\base.py:33\u001b[0m, in \u001b[0;36m_get_regex_parser_fn.<locals>._regex_parser\u001b[1;34m(output)\u001b[0m\n\u001b[0;32m     31\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(output)\n\u001b[0;32m     32\u001b[0m m \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(regex, output)\n\u001b[1;32m---> 33\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [a\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "# response = query_engine.query(\"Who won best Director in the 1972 Academy Awards?\")\n",
    "# response = query_engine.query(\"What was the precipitation in inches during June?\")\n",
    "# response = query_engine.query(\"Which televised ABC game had the greatest attendance?\")\n",
    "# response = query_engine.query(\"how many positive cases?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With embdedded csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 690.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the provided data, there are 11 instances where the third-to-last value is 1, which indicates a positive case in the target variable.\n"
     ]
    }
   ],
   "source": [
    "# # libraries\n",
    "# from pathlib import Path\n",
    "\n",
    "# # Load CSV data\n",
    "# SimpleCSVReader = download_loader(\"SimpleCSVReader\")\n",
    "# loader = SimpleCSVReader(encoding=\"utf-8\")\n",
    "# documents = loader.load_data(file=Path('./data_csv/Sepsis_Processed_IC.csv'))\n",
    "\n",
    "# file_path = \"./data_csv/Sepsis_Processed_IC.csv\"\n",
    "# documents = SimpleDirectoryReader(input_files = [file_path]).load_data()\n",
    "file_path = \"./data_csv/\"\n",
    "parser = PandasCSVReader()\n",
    "file_extractor = {\".csv\": parser}\n",
    "documents = SimpleDirectoryReader(\n",
    "    file_path, file_extractor=file_extractor\n",
    ").load_data()\n",
    "\n",
    "# Create Chroma DB client and store\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db_data\")\n",
    "chroma_collection = client.create_collection(name=\"reviewssssss\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# Initialize Ollama and ServiceContext\n",
    "llm_model = \"mistral-large-latest\"\n",
    "MISTRAL_API_KEY =  \"BWdlihu9sUh5P2g3bHnzjAaHiT4anTVH\"\n",
    "os.environ[\"MISTRAL_API_KEY\"] = MISTRAL_API_KEY\n",
    "llm = MistralAI(model=llm_model, temperature=0.0)\n",
    "embedding = \"BAAI/bge-small-en-v1.5\"\n",
    "embed_model = FastEmbedEmbedding(model_name=embedding)\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = llm\n",
    "\n",
    "# Create VectorStoreIndex and query engine with a similarity threshold of 20\n",
    "index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# Perform a query and print the response\n",
    "response = query_engine.query(\"how many positive cases in target?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading file\n",
    "file_path = \"./data_csv/Sepsis_Processed_IC.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# create prompt modules\n",
    "instruction_str = (\n",
    "    \"1. Convert the query to executable Python code using Pandas.\\n\"\n",
    "    \"2. The final line of code should be a Python expression that can be called with the `eval()` function.\\n\"\n",
    "    \"3. The code should represent a solution to the query.\\n\"\n",
    "    \"4. PRINT ONLY THE EXPRESSION.\\n\"\n",
    "    \"5. Do not quote the expression.\\n\"\n",
    ")\n",
    "\n",
    "pandas_prompt_str = (\n",
    "    \"You are working with a pandas dataframe in Python.\\n\"\n",
    "    \"The name of the dataframe is `df`.\\n\"\n",
    "    \"This is the result of `print(df.head())`:\\n\"\n",
    "    \"{df_str}\\n\\n\"\n",
    "    \"Follow these instructions:\\n\"\n",
    "    \"{instruction_str}\\n\"\n",
    "    \"Query: {query_str}\\n\\n\"\n",
    "    \"Expression:\"\n",
    ")\n",
    "response_synthesis_prompt_str = (\n",
    "    \"Given an input question, synthesize a response from the query results.\\n\"\n",
    "    \"Query: {query_str}\\n\\n\"\n",
    "    \"Pandas Instructions (optional):\\n{pandas_instructions}\\n\\n\"\n",
    "    \"Pandas Output: {pandas_output}\\n\\n\"\n",
    "    \"Response: \"\n",
    ")\n",
    "\n",
    "pandas_prompt = PromptTemplate(pandas_prompt_str).partial_format(\n",
    "    instruction_str=instruction_str, df_str=df.head(5)\n",
    ")\n",
    "pandas_output_parser = PandasInstructionParser(df)\n",
    "response_synthesis_prompt = PromptTemplate(response_synthesis_prompt_str)\n",
    "llm_model = \"mistral-large-latest\"\n",
    "MISTRAL_API_KEY =  \"BWdlihu9sUh5P2g3bHnzjAaHiT4anTVH\"\n",
    "os.environ[\"MISTRAL_API_KEY\"] = MISTRAL_API_KEY\n",
    "llm = MistralAI(model=llm_model, temperature=0.0)\n",
    "\n",
    "# query pipeline\n",
    "qp = QP(\n",
    "    modules={\n",
    "        \"input\": InputComponent(),\n",
    "        \"pandas_prompt\": pandas_prompt,\n",
    "        \"llm1\": llm,\n",
    "        \"pandas_output_parser\": pandas_output_parser,\n",
    "        \"response_synthesis_prompt\": response_synthesis_prompt,\n",
    "        \"llm2\": llm,\n",
    "    },\n",
    "    verbose=True,\n",
    ")\n",
    "qp.add_chain([\"input\", \"pandas_prompt\", \"llm1\", \"pandas_output_parser\"])\n",
    "qp.add_links(\n",
    "    [\n",
    "        Link(\"input\", \"response_synthesis_prompt\", dest_key=\"query_str\"),\n",
    "        Link(\n",
    "            \"llm1\", \"response_synthesis_prompt\", dest_key=\"pandas_instructions\"\n",
    "        ),\n",
    "        Link(\n",
    "            \"pandas_output_parser\",\n",
    "            \"response_synthesis_prompt\",\n",
    "            dest_key=\"pandas_output\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "# add link from response synthesis prompt to llm2\n",
    "qp.add_link(\"response_synthesis_prompt\", \"llm2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query_str: how many positive cases?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_prompt with input: \n",
      "query_str: how many positive cases?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm1 with input: \n",
      "messages: You are working with a pandas dataframe in Python.\n",
      "The name of the dataframe is `df`.\n",
      "This is the result of `print(df.head())`:\n",
      "  case_id  Target  age  max_activity_count  duration_since_reg  crp  \\\n",
      "0...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_output_parser with input: \n",
      "input: assistant: df[df['Target'] == 1].shape[0]\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_prompt with input: \n",
      "query_str: how many positive cases?\n",
      "pandas_instructions: assistant: df[df['Target'] == 1].shape[0]\n",
      "pandas_output: 98\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm2 with input: \n",
      "messages: Given an input question, synthesize a response from the query results.\n",
      "Query: how many positive cases?\n",
      "\n",
      "Pandas Instructions (optional):\n",
      "df[df['Target'] == 1].shape[0]\n",
      "\n",
      "Pandas Output: 98\n",
      "\n",
      "Response: \n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# run query\n",
    "response = qp.run(\n",
    "    query_str=\"how many positive cases?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the data provided, there are 98 positive cases.\n"
     ]
    }
   ],
   "source": [
    "# query result\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query_str: which age group has the highest number of positive cases?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_prompt with input: \n",
      "query_str: which age group has the highest number of positive cases?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm1 with input: \n",
      "messages: You are working with a pandas dataframe in Python.\n",
      "The name of the dataframe is `df`.\n",
      "This is the result of `print(df.head())`:\n",
      "  case_id  Target  age  max_activity_count  duration_since_reg  crp  \\\n",
      "0...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_output_parser with input: \n",
      "input: assistant: df[(df['Target'] == 1)]['age'].value_counts().idxmax()\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_prompt with input: \n",
      "query_str: which age group has the highest number of positive cases?\n",
      "pandas_instructions: assistant: df[(df['Target'] == 1)]['age'].value_counts().idxmax()\n",
      "pandas_output: 60\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm2 with input: \n",
      "messages: Given an input question, synthesize a response from the query results.\n",
      "Query: which age group has the highest number of positive cases?\n",
      "\n",
      "Pandas Instructions (optional):\n",
      "df[(df['Target'] == 1)]['age']....\n",
      "\n",
      "\u001b[0mfinal response: ================================================================================================\n",
      "The age group with the highest number of positive cases is 60 years old.\n"
     ]
    }
   ],
   "source": [
    "# run query\n",
    "response = qp.run(\n",
    "    query_str=\"which age group has the highest number of positive cases?\",\n",
    ")\n",
    "# query result\n",
    "print(\"final response: ================================================================================================\")\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query_str: what is the average time patients spend in the hospital?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_prompt with input: \n",
      "query_str: what is the average time patients spend in the hospital?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm1 with input: \n",
      "messages: You are working with a pandas dataframe in Python.\n",
      "The name of the dataframe is `df`.\n",
      "This is the result of `print(df.head())`:\n",
      "  case_id  Target  age  max_activity_count  duration_since_reg  crp  \\\n",
      "0...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_output_parser with input: \n",
      "input: assistant: df['duration_since_reg'].mean()\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_prompt with input: \n",
      "query_str: what is the average time patients spend in the hospital?\n",
      "pandas_instructions: assistant: df['duration_since_reg'].mean()\n",
      "pandas_output: 11.568710217755443\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm2 with input: \n",
      "messages: Given an input question, synthesize a response from the query results.\n",
      "Query: what is the average time patients spend in the hospital?\n",
      "\n",
      "Pandas Instructions (optional):\n",
      "df['duration_since_reg'].mean()\n",
      "...\n",
      "\n",
      "\u001b[0mfinal response: ================================================================================================\n",
      "Based on the data provided, the average time patients spend in the hospital is approximately 11.57 days.\n"
     ]
    }
   ],
   "source": [
    "# run query\n",
    "response = qp.run(\n",
    "    query_str=\"what is the average time patients spend in the hospital?\",\n",
    ")\n",
    "# query result\n",
    "print(\"final response: ================================================================================================\")\n",
    "print(response.message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
